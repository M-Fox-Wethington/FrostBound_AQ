---
title: "Sea Ice Trend Analysis - NSIDC"
author: "Michael Wethington"
date: "2024-05-14"
output: html_document
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
library(terra)

```

## **Dataset Overview**

```{r Data Overview}

nsidc_winter <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack/NSIDC_25km_Full_Study_Area.nc"

nsidc_winter <- rast(nsidc_winter)

# Print the object to see its structure
print(nsidc_winter)

# Summary of the object
summary(nsidc_winter)

str(nsidc_winter)

# If it's a SpatRaster, use terra functions to explore further
if (inherits(nsidc_winter, "SpatRaster")) {
  # Check the number of layers
  nlyr(nsidc_winter)
  
  # Extract dates from raster layer names or metadata
  winter_dates <- time(nsidc_winter)

# Extract unique months from the dates
  unique_months <- unique(month(winter_dates))
  
  print(unique_months)
  
  # Get the names of the layers
  names(nsidc_winter)
  
  # Plot a single layer
  plot(nsidc_winter[[1]])
  
  # Get the extent of the raster
  ext(nsidc_winter)
  
  # Get the resolution of the raster
  res(nsidc_winter)
  
  # Check the CRS (Coordinate Reference System)
  crs(nsidc_winter)
} else {
  print("The object is not a SpatRaster. Further exploration is needed.")
}


summary(nsidc_winter[[1]])

plot(nsidc_winter[[1]])

rm(nsidc_winter)
```




**Calculate Regional Sea Ice Metrics (Parallel)**

```{r Calculate Regional Ice Extent Metrics}


library(terra)        # For raster data manipulation
library(doParallel)   # For parallel processing
library(foreach)      # For looping with parallel support
library(dplyr)
library(lubridate)

# Function to calculate mean SIC and sea ice extent for a given raster layer within a file
calculate_layer_stats <- function(layer_index, file_path) {
  raster_stack <- rast(file_path)                  # Load the raster stack from file
  layer_data <- raster_stack[[layer_index]]        # Extract the specific layer
  
  layer_date <- time(layer_data)                   # Extract date from layer metadata

  # Handle sea ice concentration: treat cells < 15 as 0
  layer_data[layer_data < 15] <- 0
  
  # Calculate mean SIC excluding NAs
  mean_sic <- as.numeric(terra::global(layer_data, fun = 'mean', na.rm = TRUE))  
  
  # Handle sea ice extent: count cells >= 15
  valid_ice_cells <- sum(values(layer_data) >= 15, na.rm = TRUE)
  cell_area_sq_meters <- prod(res(layer_data))    # Calculate the area of one cell in square meters
  total_ice_area_sq_km <- (valid_ice_cells * cell_area_sq_meters) / 1e6  # Convert total ice area to square kilometers
  
  rm(raster_stack, layer_data)   # Clear memory
  gc()                           # Run garbage collection
  
  # Extract region name from the file path
  region_name <- tools::file_path_sans_ext(basename(file_path))
  region_name <- sub("NSIDC_25km_", "", region_name)  # Adjust based on actual pattern in filenames
  
  return(list(mean_sic = mean_sic, ice_extent_km = total_ice_area_sq_km, date = layer_date, region = region_name))
}

# Directory with chunk files for each region
chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"

chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)  # List all .nc files for each region


all_results <- list()  # Initialize list to store results from all chunks

for (r_fp in chunk_files) {
  numCores <- detectCores() - 1
  cl <- makeCluster(numCores)
  registerDoParallel(cl)
  
  clusterExport(cl, varlist = c("calculate_layer_stats", "r_fp"))
  
  results <- foreach(i = 1:nlyr(rast(r_fp)), .packages = 'terra', .errorhandling = "pass") %dopar% {
    tryCatch({
      calculate_layer_stats(i, r_fp)
    }, error = function(e) {
      return(list(error = TRUE, message = e$message))
    })
  }
  
  stopCluster(cl)
  
  # Append chunk results to overall results, add file path to results for region tracking
  all_results <- c(all_results, lapply(results, function(x) c(x, file = r_fp)))
}

# Convert list of all results into a dataframe, handling possible errors
final_result_df <- do.call(rbind, lapply(all_results, function(x) {
  if (!is.null(x$error)) {
    return(data.frame(Date = NA, MeanSIC = NA, IceExtent_km = NA, Region = NA, error = x$message))
  } else {
    return(data.frame(Date = x$date, MeanSIC = x$mean_sic, IceExtent_km = x$ice_extent_km, Region = x$region, error = NA))
  }
}))

# Add year, month, and day columns
final_result_df <- final_result_df %>%
  dplyr::mutate(Year = year(Date), Month = month(Date), Day = day(Date))

# Filter for Full_Study_Area and June, July, August, and September
final_result_df <- final_result_df %>%
  filter(Month %in% c(6, 7, 8, 9))

# Save combined results to CSV and RDS for further use
write.csv(final_result_df, "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.csv", row.names = FALSE)
saveRDS(final_result_df, "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")



```




**Sea Ice Persistence Trend**


```{r}

# Load necessary libraries
library(terra)
library(viridis)
library(dplyr)
library(lubridate)
library(nlme)
library(sf) # For handling shapefiles

# Load the NSIDC sea ice concentration data
nsidc <- rast("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/NSIDC_25km_Study-Area.nc")

# Filter the sea ice data from 1980 to 2022
start_date <- as.Date("1980-01-01")
end_date <- as.Date("2022-12-31")
nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))

# Extract all years for processing
all_years <- unique(year(time(nsidc)))

# Define winter months (June-September)
winter_months <- list(
  June = 6,
  July = 7,
  August = 8,
  September = 9
)

# Define a function to count days with ice cover > 15% for each year
count_ice_days <- function(x) {
  ice_days <- sum(x > 15, na.rm = TRUE)
  return(ice_days)
}

# Function to process annual and monthly ice persistence
process_ice_persistence <- function(nsidc, years, months = NULL) {
  ice_days_list <- list()
  for (year in years) {
    if (is.null(months)) {
      year_rasters <- subset(nsidc, year(time(nsidc)) == year)
    } else {
      year_rasters <- subset(nsidc, which(year(time(nsidc)) == year & month(time(nsidc)) %in% months))
    }
    if (nlyr(year_rasters) > 0) {
      ice_days_raster <- app(year_rasters, count_ice_days)
      names(ice_days_raster) <- paste("Ice_Days", year, sep = "_")
      ice_days_list[[as.character(year)]] <- ice_days_raster
      print(paste("Processed year:", year, "month:", ifelse(is.null(months), "Annual", paste(months, collapse = ","))))
    } else {
      print(paste("No data for year:", year, "month:", ifelse(is.null(months), "Annual", paste(months, collapse = ","))))
    }
  }
  ice_days_stack <- rast(ice_days_list)
  return(mask(ice_days_stack, nsidc[[1]], maskvalues = NA))
}

# Calculate annual ice persistence
annual_ice_days_stack <- process_ice_persistence(nsidc, all_years)

# Calculate monthly ice persistence
monthly_ice_days_stacks <- lapply(winter_months, function(month) {
  process_ice_persistence(nsidc, all_years, month)
})

# Load the study area shapefile
study_area <- st_read("D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp")

# Mask the sea ice persistence rasters to the study area
mask_to_study_area <- function(raster_stack, study_area) {
  mask(raster_stack, vect(study_area))
}

# Apply the mask to the study area for annual and monthly data
annual_ice_days_stack_masked <- mask_to_study_area(annual_ice_days_stack, study_area)
monthly_ice_days_stacks_masked <- lapply(monthly_ice_days_stacks, mask_to_study_area, study_area)

# Function to calculate slope for each pixel
calculate_slope <- function(values, years) {
  model <- lm(values ~ years)
  return(coef(model)[2])  # Extract the slope coefficient
}

# Calculate slope for annual ice persistence
slope_raster_annual <- annual_ice_days_stack_masked[[1]]
values(slope_raster_annual) <- NA

for (i in 1:ncell(annual_ice_days_stack_masked)) {
  pixel_values <- values(annual_ice_days_stack_masked)[i, ]
  if (all(is.na(pixel_values))) next
  slope_raster_annual[i] <- calculate_slope(pixel_values, all_years)
}

# Calculate slopes for monthly ice persistence
slope_rasters_monthly <- lapply(monthly_ice_days_stacks_masked, function(stack) {
  slope_raster <- stack[[1]]
  values(slope_raster) <- NA
  for (i in 1:ncell(stack)) {
    pixel_values <- values(stack)[i, ]
    if (all(is.na(pixel_values))) next
    slope_raster[i] <- calculate_slope(pixel_values, all_years)
  }
  return(slope_raster)
})

# Function to convert slopes to days of ice cover change per year
convert_to_days <- function(slope_raster, period_length) {
  return(slope_raster * period_length)
}

# Calculate the length of the study period in years
period_length <- length(all_years)

# Convert the slopes to days of ice cover change per year
slope_raster_annual_days <- convert_to_days(slope_raster_annual, period_length)
slope_rasters_monthly_days <- lapply(slope_rasters_monthly, convert_to_days, period_length)

# Determine the common range for the color scale without normalization
all_rasters_days <- c(list(slope_raster_annual_days), slope_rasters_monthly_days)
common_range_days <- range(sapply(all_rasters_days, function(r) range(values(r), na.rm = TRUE)))

# Visualize the trends for annual and monthly ice persistence with a common color scale
par(mfrow = c(2, 3))
plot(slope_raster_annual_days, main = "Annual Sea Ice Persistence Trend (1980-2022)", 
     col = viridis(100, option = "D"), zlim = common_range_days, colNA = "white")
plot(slope_rasters_monthly_days[[1]], main = "June Sea Ice Persistence Trend (1980-2022)", 
     col = viridis(100, option = "D"), zlim = common_range_days, colNA = "white")
plot(slope_rasters_monthly_days[[2]], main = "July Sea Ice Persistence Trend (1980-2022)", 
     col = viridis(100, option = "D"), zlim = common_range_days, colNA = "white")
plot(slope_rasters_monthly_days[[3]], main = "August Sea Ice Persistence Trend (1980-2022)", 
     col = viridis(100, option = "D"), zlim = common_range_days, colNA = "white")
plot(slope_rasters_monthly_days[[4]], main = "September Sea Ice Persistence Trend (1980-2022)", 
     col = viridis(100, option = "D"), zlim = common_range_days, colNA = "white")

# Adding legends
legend("bottomleft", legend = c("Decrease", "Increase"), fill = c("red", "blue"), title = "Sea Ice Change (days/year)")





```








**Extent: Sea Ice Analysis: Generalized Least Squares**


```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(nlme)
library(wesanderson)
library(scales)

# Load your dataset
nsidc_metrics <- readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of ice extent for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_extent = mean(IceExtent_km, na.rm = TRUE), 
            sd_extent = sd(IceExtent_km, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Define a function to fit a GLS model for a given region and month
fit_gls_model <- function(region_data) {
  gls_model <- gls(mean_extent ~ Time, correlation = corAR1(), data = region_data)
  return(gls_model)
}

# Apply the model for each unique region and month combination and store the results
regions <- unique(monthly_averages$Region)
months <- unique(monthly_averages$Month)
gls_results <- list()

for (region in regions) {
  for (month in months) {
    region_month_data <- monthly_averages %>% filter(Region == region, Month == month)
    if (nrow(region_month_data) > 1) {
      gls_results[[paste(region, month, sep = "_")]] <- fit_gls_model(region_month_data)
    }
  }
}

# Display summary of the GLS model for each region and month
for (key in names(gls_results)) {
  cat("Region and Month:", key, "\n")
  print(summary(gls_results[[key]]))
  cat("\n")
}

# Directory to save the plots
output_directory <- "D:/Manuscripts_localData/FrostBound_AQ/Results/gls_trends"
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

# Color settings
sd_color <- "#7AB8BF"  # Light red color (you can adjust to your preferred shade)
axis_color <- "gray70"  # Light gray color for the axis lines

# Visualize the trend for each region and save the plots
for (region in regions) {
  region_data <- monthly_averages %>% filter(Region == region)
  
  p <- region_data %>%
    ggplot(aes(x = Year, y = mean_extent)) +
    geom_errorbar(aes(ymin = mean_extent - sd_extent, ymax = mean_extent + sd_extent), 
                  width = 0.2, color = sd_color) +
    geom_point(color = "black") +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    facet_wrap(~month2, scales = "fixed", ncol = 3) +
    xlab(NULL) +
    ylab(bquote("Ice extent" ~ (km^2 %*% 10^6))) +
    scale_y_continuous(labels = scales::scientific) +
    labs(
      title = sprintf(
        "%s: Sea ice extent between %d and %d",
        region,
        min(region_data$Year),
        max(region_data$Year)
      ),
      # subtitle = "The vertical bar at each point shows the standard deviation around the mean. The blue line represents the linear trend.",
      caption = "Source: NSIDC 25.5 km Sea Ice Index dataset"
    ) +
    theme(
      plot.caption = element_text(size = 8, color = "black"),
      plot.margin = unit(c(5.5, 10, 5.5, 5.5), "points"),
      panel.background = element_rect(fill = "white"),
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(colour = "black", size = 12, face = "bold"),
      panel.grid = element_blank(),
      axis.line = element_line(color = axis_color),
      legend.position = "none"
    )
  
  # Save the plot
  ggsave(filename = paste(output_directory, paste("25km_Extent_trend_plot_", region, ".png", sep = ""), sep = "/"), plot = p)
  

  # Save the plot as EPS
  ggsave(filename = paste(output_directory, paste("25km_Extent_trend_plot_", region, ".eps", sep = ""), sep = "/"), plot = p, device = "eps")
}


# Extract and print coefficients and p-values for each region and month
coefficients_gls <- lapply(gls_results, function(model) summary(model)$tTable)
names(coefficients_gls) <- names(gls_results)

# Print coefficients and p-values
for (key in names(coefficients_gls)) {
  cat("Region and Month:", key, "\n")
  print(coefficients_gls[[key]])
  cat("\n")
}


```





**Concentration: Sea Ice Analysis - Generalized Least Squares**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(nlme)
library(wesanderson)
library(scales)

# Load your dataset
nsidc_metrics <-readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

str(nsidc_metrics)
# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of sea ice concentration for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_concentration = mean(MeanSIC, na.rm = TRUE), 
            sd_concentration = sd(MeanSIC, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Define a function to fit a GLS model for a given region and month
fit_gls_model <- function(region_data) {
  gls_model <- gls(mean_concentration ~ Time, correlation = corAR1(), data = region_data)
  return(gls_model)
}

# Apply the model for each unique region and month combination and store the results
regions <- unique(monthly_averages$Region)
months <- unique(monthly_averages$Month)
gls_results <- list()

for (region in regions) {
  for (month in months) {
    region_month_data <- monthly_averages %>% filter(Region == region, Month == month)
    if (nrow(region_month_data) > 1) {
      gls_results[[paste(region, month, sep = "_")]] <- fit_gls_model(region_month_data)
    }
  }
}

# Display summary of the GLS model for each region and month
for (key in names(gls_results)) {
  cat("Region and Month:", key, "\n")
  print(summary(gls_results[[key]]))
  cat("\n")
}

# Directory to save the plots
output_directory <- "D:/Manuscripts_localData/FrostBound_AQ/Results/gls_trends"
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

# Color settings
sd_color <- "#7AB8BF"  # Light red color 
axis_color <- "gray70"  # Light gray color for the axis lines

# Visualize the trend for each region and save the plots
for (region in regions) {
  region_data <- monthly_averages %>% filter(Region == region)
  
  p <- region_data %>%
    ggplot(aes(x = Year, y = mean_concentration)) +
    geom_errorbar(aes(ymin = mean_concentration - sd_concentration, ymax = mean_concentration + sd_concentration), 
                  width = 0.2, color = sd_color) +
    geom_point(color = "black") +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    facet_wrap(~month2, scales = "fixed", ncol = 3) +
    xlab(NULL) +
    ylab("Mean Sea Ice Concentration (%)") +
    labs(
      title = sprintf(
        "%s: Sea ice concentration between %d and %d",
        region,
        min(region_data$Year),
        max(region_data$Year)
      ),
      subtitle = "The vertical bar at each point shows the standard deviation around the mean. The blue line represents the linear trend.",
      caption = "Source: NSIDC 25km Sea Ice Index dataset"
    ) +
    theme(
      plot.caption = element_text(size = 8, color = "black"),
      plot.margin = unit(c(5.5, 10, 5.5, 5.5), "points"),
      panel.background = element_rect(fill = "white"),
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(colour = "black", size = 12, face = "bold"),
      panel.grid = element_blank(),
      axis.line = element_line(color = axis_color),
      legend.position = "none"
    )
  
  # Save the plot
  ggsave(filename = paste(output_directory, paste("25km_Concentration_trend_plot_", region, ".png", sep = ""), sep = "/"), plot = p)
  
  # Save the plot as EPS
  ggsave(filename = paste(output_directory, paste("25km_Concentration_trend_plot_", region, ".eps", sep = ""), sep = "/"), plot = p, device = "eps")
}

# Extract and print coefficients and p-values for each region and month
coefficients_gls <- lapply(gls_results, function(model) summary(model)$tTable)
names(coefficients_gls) <- names(gls_results)

# Print coefficients and p-values
for (key in names(coefficients_gls)) {
  cat("Region and Month:", key, "\n")
  print(coefficients_gls[[key]])
  cat("\n")
}


```


**Southern Oscillation Index Analysis**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(httr)
library(tidyr)
library(broom)
library(gridExtra)
library(RColorBrewer)

# Load your dataset
nsidc_metrics <- readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of ice extent for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_extent = mean(IceExtent_km, na.rm = TRUE), 
            sd_extent = sd(IceExtent_km, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Load SOI data
url <- "https://www.cpc.ncep.noaa.gov/data/indices/soi"
soi_raw <- GET(url)
soi_text <- content(soi_raw, "text")

# Preprocess the SOI data
soi_lines <- strsplit(soi_text, "\n")[[1]]

# Identify the start of the standardized SOI data section
standardized_soi_start <- grep("STANDARDIZED    DATA", soi_lines)

# Extract standardized SOI data lines
soi_standardized_lines <- soi_lines[(standardized_soi_start + 3):length(soi_lines)]
soi_standardized_lines <- soi_standardized_lines[!grepl("-999.9", soi_standardized_lines)] # remove lines with invalid data

# Convert standardized SOI data to dataframe
soi_data <- read.table(text = soi_standardized_lines, fill = TRUE, stringsAsFactors = FALSE)
colnames(soi_data) <- c("Year", month.abb)
soi_data <- soi_data %>% mutate(Year = as.integer(Year))

# Convert to long format
soi_data_long <- soi_data %>%
  pivot_longer(-Year, names_to = "Month", values_to = "SOI") %>%
  mutate(Month = match(Month, month.abb), 
         Year = as.integer(Year),
         SOI = as.numeric(SOI)) %>%
  filter(!is.na(SOI))  # Remove rows with NA values in SOI

# Merge sea ice data with SOI data
merged_data <- merge(monthly_averages, soi_data_long, by = c("Year", "Month"))

# Remove duplicate rows
merged_data <- merged_data[!duplicated(merged_data), ]

# Calculate correlation for each region and month
correlation_results <- merged_data %>%
  group_by(Region, Month) %>%
  summarize(correlation = cor(mean_extent, SOI, use = "complete.obs"),
            p.value = cor.test(mean_extent, SOI)$p.value) %>%
  arrange(Region, Month)

# Print the correlation results
print(correlation_results)




# Visualize the correlation results using RColorBrewer color palette
ggplot(correlation_results, aes(x = factor(Month, levels = 6:9), y = correlation, fill = Region)) +
  geom_bar(stat = "identity", position = position_dodge(0.9)) +
  geom_text(aes(label = round(correlation, 2)), vjust = -1.5, position = position_dodge(0.9)) +
  scale_fill_brewer(palette = "Set3") +  # You can choose other palettes like "Paired", "Dark2", etc.
  labs(title = "Correlation between SOI and Sea Ice Extent by Region and Month",
       x = "Month", y = "Correlation") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom"
  )




# Linear regression analysis to quantify the relationship between SOI and sea ice extent
regression_results <- merged_data %>%
  group_by(Region, Month) %>%
  do(tidy(lm(mean_extent ~ SOI, data = .)))

# Print regression results
print(regression_results)

# Filter the regression results for the SOI term
soi_coefficients <- regression_results %>%
  filter(term == "SOI")

# Function to create a plot for each region
plot_soi_effect <- function(region_data) {
  ggplot(region_data, aes(x = factor(Month), y = estimate, color = factor(Month))) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(
      title = paste("Effect of SOI on Sea Ice Extent:", unique(region_data$Region)),
      x = "Month",
      y = "SOI Coefficient Estimate",
      color = "Month"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5),
      legend.position = "none"
    )
}

# Apply the function for each region and plot
unique_regions <- unique(soi_coefficients$Region)
plots <- lapply(unique_regions, function(region) {
  region_data <- soi_coefficients %>% filter(Region == region)
  plot_soi_effect(region_data)
})

# Display the plots
do.call(grid.arrange, c(plots, ncol = 2))

# # Create a combined plot showing the SOI coefficients for all regions and months
# ggplot(soi_coefficients, aes(x = factor(Month), y = estimate, color = Region)) +
#   geom_point(size = 3) +
#   geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
#   geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
#   labs(
#     title = "Effect of SOI on Sea Ice Extent Across Regions and Months",
#     x = "Month",
#     y = "SOI Coefficient Estimate",
#     color = "Region"
#   ) +
#   theme_minimal() +
#   theme(
#     plot.title = element_text(hjust = 0.5)
  # )

# Create individual plots for each region and arrange them using facet_wrap
ggplot(soi_coefficients, aes(x = factor(Month), y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~ Region, scales = "free_y") +
  labs(
    title = "Effect of SOI on Sea Ice Extent Across Regions and Months",
    x = "Month",
    y = "SOI Coefficient Estimate"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )


```



**Gentoo Penguin Abundance Analysis**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)

# Load your Gentoo penguin dataset
gentoo_file_path <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/GentooCounts_48_1.csv"
gentoo_data <- read.csv(gentoo_file_path)

# Filter to include only nests and years starting from 1995
gentoo_data <- gentoo_data %>%
  filter(count_type == "nests" & season_starting >= 1995)

# Check the structure of the filtered data
str(gentoo_data)

# Aggregate counts by averaging for each site per season, then standardize by the number of sites visited
annual_abundance <- gentoo_data %>%
  group_by(season_starting, site_name) %>%
  summarise(avg_abundance = mean(penguin_count, na.rm = TRUE), .groups = 'drop') %>%
  group_by(season_starting) %>%
  summarise(total_abundance = sum(avg_abundance, na.rm = TRUE), 
            num_sites = n_distinct(site_name), .groups = 'drop') %>%
  mutate(standardized_abundance = total_abundance / num_sites)

# Print annual_abundance for verification
print("Annual abundance data:")
print(head(annual_abundance))

# Load your sea ice concentration dataset
sea_ice_file_path <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds"
nsidc_metrics <- readRDS(sea_ice_file_path)

# Add Year, Month, and Day columns to sea ice data
sea_ice_data <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date))

# Check the structure of the sea_ice_data
str(sea_ice_data)

# Calculate the average sea ice concentration for each month (June, July, August, September) for each year
monthly_sea_ice <- sea_ice_data %>%
  filter(Month %in% c(6, 7, 8, 9)) %>%
  group_by(Year, Month) %>%
  summarise(average_concentration = mean(MeanSIC, na.rm = TRUE), .groups = 'drop')

# Print monthly_sea_ice for verification
print("Monthly sea ice data:")
print(head(monthly_sea_ice))

# Function to calculate sub-seasonal correlations for different lag periods
calculate_subseasonal_correlation <- function(month, lag) {
  monthly_data <- monthly_sea_ice %>%
    filter(Month == month) %>%
    mutate(Year_lagged = Year + lag) %>%
    select(Year_lagged, average_concentration)
  
  # Inspect the monthly data for debugging
  print(paste("Monthly data for month:", month, "with lag:", lag))
  print(head(monthly_data))
  
  correlation_results_monthly <- annual_abundance %>%
    inner_join(monthly_data, by = c("season_starting" = "Year_lagged"))
  
  # Inspect the join results for debugging
  print(paste("Join results for month:", month, "with lag:", lag))
  print(head(correlation_results_monthly))
  
  if (nrow(correlation_results_monthly) > 0) {
    correlation_value_monthly <- cor(correlation_results_monthly$standardized_abundance, correlation_results_monthly$average_concentration, use = "complete.obs")
  } else {
    correlation_value_monthly <- NA
  }
  
  return(correlation_value_monthly)
}

# Calculate correlations for each month (June, July, August, September) and for each lag (1 to 6 years)
months <- c(6, 7, 8, 9)
month_names <- c("June", "July", "August", "September")
lags <- 1:6
subseasonal_correlations <- expand.grid(months, lags) %>%
  apply(1, function(x) calculate_subseasonal_correlation(x[1], x[2]))

# Convert the correlation results to a data frame
subseasonal_correlation_df <- expand.grid(Month = factor(month_names, levels = month_names), Lag = lags)
subseasonal_correlation_df$Correlation <- subseasonal_correlations

# Print sub-seasonal correlation results
for (i in seq_along(subseasonal_correlations)) {
  cat("Correlation between Gentoo penguin abundance and average sea ice concentration in", 
      subseasonal_correlation_df$Month[i], "with", subseasonal_correlation_df$Lag[i], "year lag (starting from 1995):", 
      subseasonal_correlation_df$Correlation[i], "\n")
}

# Plot sub-seasonal correlations
plot_subseasonal_correlations <- ggplot(subseasonal_correlation_df, aes(x = Lag, y = Correlation, color = Month)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Correlation between Gentoo Penguin Abundance and Lagged Sea Ice Concentration",
    x = "Lag Period (Years)",
    y = "Correlation Coefficient"
  ) +
  theme_minimal()

# Save the sub-seasonal correlation plot
ggsave("D:/Manuscripts_localData/FrostBound_AQ/Results/subseasonal_correlations_plot.png", plot_subseasonal_correlations)

# Display the sub-seasonal correlation plot
print(plot_subseasonal_correlations)



```







```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```
