---
title: "Sea Ice Trend Analysis - NSIDC"
author: "Michael Wethington"
date: "2024-05-14"
output: html_document
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
library(terra)

```

## **Dataset Overview**

```{r Data Overview}

nsidc_winter <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack/NSIDC_25km_Full_Study_Area.nc"

nsidc_winter <- rast(nsidc_winter)

# Print the object to see its structure
print(nsidc_winter)

# Summary of the object
summary(nsidc_winter)

str(nsidc_winter)

# If it's a SpatRaster, use terra functions to explore further
if (inherits(nsidc_winter, "SpatRaster")) {
  # Check the number of layers
  nlyr(nsidc_winter)
  
  # Extract dates from raster layer names or metadata
  winter_dates <- time(nsidc_winter)

# Extract unique months from the dates
  unique_months <- unique(month(winter_dates))
  
  print(unique_months)
  
  # Get the names of the layers
  names(nsidc_winter)
  
  # Plot a single layer
  plot(nsidc_winter[[1]])
  
  # Get the extent of the raster
  ext(nsidc_winter)
  
  # Get the resolution of the raster
  res(nsidc_winter)
  
  # Check the CRS (Coordinate Reference System)
  crs(nsidc_winter)
} else {
  print("The object is not a SpatRaster. Further exploration is needed.")
}


summary(nsidc_winter[[1]])

plot(nsidc_winter[[1]])

rm(nsidc_winter)
```




**Calculate Sea Ice Extent and Concentration (Parallel)**

```{r Calculate Regional Ice Extent Metrics}


library(terra)        # For raster data manipulation
library(doParallel)   # For parallel processing
library(foreach)      # For looping with parallel support
library(dplyr)
library(lubridate)

# Function to calculate mean SIC and sea ice extent for a given raster layer within a file
calculate_layer_stats <- function(layer_index, file_path) {
  raster_stack <- rast(file_path)                  # Load the raster stack from file
  layer_data <- raster_stack[[layer_index]]        # Extract the specific layer
  
  layer_date <- time(layer_data)                   # Extract date from layer metadata

  # Handle sea ice concentration: treat cells < 15 as 0
  layer_data[layer_data < 15] <- 0
  
  # Calculate mean SIC excluding NAs
  mean_sic <- as.numeric(terra::global(layer_data, fun = 'mean', na.rm = TRUE))  
  
  # Handle sea ice extent: count cells >= 15
  valid_ice_cells <- sum(values(layer_data) >= 15, na.rm = TRUE)
  cell_area_sq_meters <- prod(res(layer_data))    # Calculate the area of one cell in square meters
  total_ice_area_sq_km <- (valid_ice_cells * cell_area_sq_meters) / 1e6  # Convert total ice area to square kilometers
  
  rm(raster_stack, layer_data)   # Clear memory
  gc()                           # Run garbage collection
  
  # Extract region name from the file path
  region_name <- tools::file_path_sans_ext(basename(file_path))
  region_name <- sub("NSIDC_25km_", "", region_name)  # Adjust based on actual pattern in filenames
  
  return(list(mean_sic = mean_sic, ice_extent_km = total_ice_area_sq_km, date = layer_date, region = region_name))
}

# Directory with chunk files for each region
chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"

chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)  # List all .nc files for each region


all_results <- list()  # Initialize list to store results from all chunks

for (r_fp in chunk_files) {
  numCores <- detectCores() - 1
  cl <- makeCluster(numCores)
  registerDoParallel(cl)
  
  clusterExport(cl, varlist = c("calculate_layer_stats", "r_fp"))
  
  results <- foreach(i = 1:nlyr(rast(r_fp)), .packages = 'terra', .errorhandling = "pass") %dopar% {
    tryCatch({
      calculate_layer_stats(i, r_fp)
    }, error = function(e) {
      return(list(error = TRUE, message = e$message))
    })
  }
  
  stopCluster(cl)
  
  # Append chunk results to overall results, add file path to results for region tracking
  all_results <- c(all_results, lapply(results, function(x) c(x, file = r_fp)))
}

# Convert list of all results into a dataframe, handling possible errors
final_result_df <- do.call(rbind, lapply(all_results, function(x) {
  if (!is.null(x$error)) {
    return(data.frame(Date = NA, MeanSIC = NA, IceExtent_km = NA, Region = NA, error = x$message))
  } else {
    return(data.frame(Date = x$date, MeanSIC = x$mean_sic, IceExtent_km = x$ice_extent_km, Region = x$region, error = NA))
  }
}))

# Add year, month, and day columns
final_result_df <- final_result_df %>%
  dplyr::mutate(Year = year(Date), Month = month(Date), Day = day(Date))

# Filter for Full_Study_Area and June, July, August, and September
final_result_df <- final_result_df %>%
  filter(Month %in% c(6, 7, 8, 9))

# Save combined results to CSV and RDS for further use
write.csv(final_result_df, "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.csv", row.names = FALSE)
saveRDS(final_result_df, "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")



```



**Calculate: Sea Ice Persistence and Duration**

```{r}
# Load necessary libraries
library(terra)
library(dplyr)
library(lubridate)
library(nlme)
library(ggplot2)
library(grDevices)  # For colorRampPalette
library(gridExtra)  # For arranging plots side by side

# Define the function
analyze_sea_ice <- function(start_year, end_year, use_mask = TRUE, report_metrics = c("concentration", "duration", "persistence")) {
  
  # Define file paths
  chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"
  chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)
  study_area_shapefile <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp"
  
  # Load the study area shapefile
  if (use_mask) {
    study_area <- vect(study_area_shapefile)
  }
  
  # Define the threshold for sea ice concentration
  ice_threshold <- 15
  
  # Function to calculate consecutive days above threshold
  calculate_duration <- function(x, threshold) {
    if (all(is.na(x))) return(NA)
    rle_result <- rle(x > threshold)
    max_duration <- ifelse(any(rle_result$values), max(rle_result$lengths[rle_result$values]), 0)
    return(max_duration)
  }
  
  # Simplified function to process each chunk file using app
  process_chunk <- function(file_path) {
    region_name <- gsub(".*/|\\.nc$", "", file_path)
    message(paste("Processing file:", file_path))
    
    # Load the NSIDC sea ice concentration data for the subregion
    nsidc <- rast(file_path)
    
    annual_persistence <- list()
    annual_duration <- list()
    annual_concentration <- list()
    
    for (year in start_year:end_year) {
      message(paste("Processing year:", year))
      start_date <- as.Date(paste0(year, "-01-01"))
      end_date <- as.Date(paste0(year, "-12-31"))
      
      # Filter the sea ice data for the current year
      nsidc_year <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))
      
      if (nlyr(nsidc_year) == 0) {
        message(paste("No data for year:", year))
        next
      }
      
      # Calculate metrics based on options
      if ("persistence" %in% report_metrics) {
        persistence <- app(nsidc_year, function(x) sum(x > ice_threshold, na.rm = TRUE))
        names(persistence) <- paste0("Persistence_", year)
        annual_persistence[[as.character(year)]] <- persistence
      }
      
      if ("duration" %in% report_metrics) {
        duration <- app(nsidc_year, function(x) calculate_duration(x, ice_threshold))
        names(duration) <- paste0("Duration_", year)
        annual_duration[[as.character(year)]] <- duration
      }
      
      if ("concentration" %in% report_metrics) {
        concentration <- app(nsidc_year, function(x) mean(x, na.rm = TRUE))
        names(concentration) <- paste0("Concentration_", year)
        annual_concentration[[as.character(year)]] <- concentration
      }
    }
    
    message(paste("Finished processing file:", file_path))
    return(list(persistence = annual_persistence, duration = annual_duration, concentration = annual_concentration))
  }
  
  # Process each chunk file sequentially
  results <- lapply(chunk_files, process_chunk)
  
  # Combine all annual rasters into a single stack for the selected metrics
  combine_rasters <- function(raster_list) {
    raster_stack <- rast()
    for (year in names(raster_list)) {
      if (!is.null(raster_list[[year]])) {
        raster_stack <- c(raster_stack, raster_list[[year]])
      }
    }
    return(raster_stack)
  }
  
  persistence_stack <- NULL
  duration_stack <- NULL
  concentration_stack <- NULL
  
  if ("persistence" %in% report_metrics) {
    persistence_stack <- combine_rasters(do.call(c, lapply(results, `[[`, "persistence")))
    if (use_mask) persistence_stack <- mask(persistence_stack, study_area)
  }
  
  if ("duration" %in% report_metrics) {
    duration_stack <- combine_rasters(do.call(c, lapply(results, `[[`, "duration")))
    if (use_mask) duration_stack <- mask(duration_stack, study_area)
  }
  
  if ("concentration" %in% report_metrics) {
    concentration_stack <- combine_rasters(do.call(c, lapply(results, `[[`, "concentration")))
    if (use_mask) concentration_stack <- mask(concentration_stack, study_area)
  }
  
  # Function to apply linear model to each pixel and return slope and p-value
  apply_lm <- function(y) {
    if (all(is.na(y))) {
      return(c(NA, NA))
    } else {
      years <- start_year:end_year
      fit <- tryCatch(lm(y ~ years), error = function(e) return(NULL))
      if (is.null(fit)) {
        return(c(NA, NA))
      } else {
        slope <- coef(fit)[2]  # Slope of the linear model
        p_value <- summary(fit)$coefficients[2, 4]  # p-value for the slope
        return(c(slope, p_value))
      }
    }
  }
  
  persistence_trend <- NULL
  duration_trend <- NULL
  concentration_trend <- NULL
  
  if (!is.null(persistence_stack)) persistence_trend <- app(persistence_stack, apply_lm)
  if (!is.null(duration_stack)) duration_trend <- app(duration_stack, apply_lm)
  if (!is.null(concentration_stack)) concentration_trend <- app(concentration_stack, apply_lm)
  
  # Extract slopes and p-values from the results
  persistence_slope <- NULL
  persistence_pvalue <- NULL
  duration_slope <- NULL
  duration_pvalue <- NULL
  concentration_slope <- NULL
  concentration_pvalue <- NULL
  
  if (!is.null(persistence_trend)) {
    persistence_slope <- persistence_trend[[1]]
    persistence_pvalue <- persistence_trend[[2]]
  }
  
  if (!is.null(duration_trend)) {
    duration_slope <- duration_trend[[1]]
    duration_pvalue <- duration_trend[[2]]
  }
  
  if (!is.null(concentration_trend)) {
    concentration_slope <- concentration_trend[[1]]
    concentration_pvalue <- concentration_trend[[2]]
  }
  
  # Verify the integrity of the data
  if (!is.null(persistence_slope)) {
    print("Summary of persistence slope layer:")
    print(summary(persistence_slope))
    print("Summary of persistence p-value layer:")
    print(summary(persistence_pvalue))
  }
  
  if (!is.null(duration_slope)) {
    print("Summary of duration slope layer:")
    print(summary(duration_slope))
    print("Summary of duration p-value layer:")
    print(summary(duration_pvalue))
  }
  
  if (!is.null(concentration_slope)) {
    print("Summary of concentration slope layer:")
    print(summary(concentration_slope))
    print("Summary of concentration p-value layer:")
    print(summary(concentration_pvalue))
  }
  
  # Define a significance level
  alpha <- 0.05
  
  # Calculate statistics for persistence
  if (!is.null(persistence_slope)) {
    persistence_values <- values(persistence_slope)
    persistence_pvalues <- values(persistence_pvalue)
    persistence_data <- cbind(persistence_values, persistence_pvalues)
    persistence_data <- persistence_data[complete.cases(persistence_data), ]
    persistence_values <- persistence_data[, 1]
    persistence_pvalues <- persistence_data[, 2]
    persistence_mean <- mean(persistence_values)
    persistence_median <- median(persistence_values)
    persistence_min <- min(persistence_values)
    persistence_max <- max(persistence_values)
    persistence_significant <- sum(persistence_pvalues <= alpha) / length(persistence_pvalues) * 100
    persistence_positive <- sum(persistence_pvalues <= alpha & persistence_values > 0) / length(persistence_pvalues) * 100
    persistence_negative <- sum(persistence_pvalues <= alpha & persistence_values < 0) / length(persistence_pvalues) * 100
    persistence_nonsignificant <- 100 - persistence_significant
  }
  
  # Calculate statistics for duration
  if (!is.null(duration_slope)) {
    duration_values <- values(duration_slope)
    duration_pvalues <- values(duration_pvalue)
    duration_data <- cbind(duration_values, duration_pvalues)
    duration_data <- duration_data[complete.cases(duration_data), ]
    duration_values <- duration_data[, 1]
    duration_pvalues <- duration_data[, 2]
    duration_mean <- mean(duration_values)
    duration_median <- median(duration_values)
    duration_min <- min(duration_values)
    duration_max <- max(duration_values)
    duration_significant <- sum(duration_pvalues <= alpha) / length(duration_pvalues) * 100
    duration_positive <- sum(duration_pvalues <= alpha & duration_values > 0) / length(duration_pvalues) * 100
    duration_negative <- sum(duration_pvalues <= alpha & duration_values < 0) / length(duration_pvalues) * 100
    duration_nonsignificant <- 100 - duration_significant
  }
  
  # Calculate statistics for concentration
  if (!is.null(concentration_slope)) {
    concentration_values <- values(concentration_slope)
    concentration_pvalues <- values(concentration_pvalue)
    concentration_data <- cbind(concentration_values, concentration_pvalues)
    concentration_data <- concentration_data[complete.cases(concentration_data), ]
    concentration_values <- concentration_data[, 1]
    concentration_pvalues <- concentration_data[, 2]
    concentration_mean <- mean(concentration_values)
    concentration_median <- median(concentration_values)
    concentration_min <- min(concentration_values)
    concentration_max <- max(concentration_values)
    concentration_significant <- sum(concentration_pvalues <= alpha) / length(concentration_pvalues) * 100
    concentration_positive <- sum(concentration_pvalues <= alpha & concentration_values > 0) / length(concentration_pvalues) * 100
    concentration_negative <- sum(concentration_pvalues <= alpha & concentration_values < 0) / length(concentration_pvalues) * 100
    concentration_nonsignificant <- 100 - concentration_significant
  }
  
  # Print summary statistics for reporting
  if (!is.null(persistence_slope)) {
    persistence_summary <- data.frame(
      Metric = c("Mean slope", "Median slope", "Minimum slope", "Maximum slope", "% Significant", "% Positive", "% Negative", "% Non-significant"),
      Persistence = c(persistence_mean, persistence_median, persistence_min, persistence_max, persistence_significant, persistence_positive, persistence_negative, persistence_nonsignificant)
    )
    print(persistence_summary)
  }
  
  if (!is.null(duration_slope)) {
    duration_summary <- data.frame(
      Metric = c("Mean slope", "Median slope", "Minimum slope", "Maximum slope", "% Significant", "% Positive", "% Negative", "% Non-significant"),
      Duration = c(duration_mean, duration_median, duration_min, duration_max, duration_significant, duration_positive, duration_negative, duration_nonsignificant)
    )
    print(duration_summary)
  }
  
  if (!is.null(concentration_slope)) {
    concentration_summary <- data.frame(
      Metric = c("Mean slope", "Median slope", "Minimum slope", "Maximum slope", "% Significant", "% Positive", "% Negative", "% Non-significant"),
      Concentration = c(concentration_mean, concentration_median, concentration_min, concentration_max, concentration_significant, concentration_positive, concentration_negative, concentration_nonsignificant)
    )
    print(concentration_summary)
  }
  
  # Define a color palette for trends
  trend_colors <- colorRampPalette(c("red", "white", "blue"))
  
  # Set up multi-panel plotting environment
  par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))
  
  if (!is.null(persistence_slope)) {
    plot(persistence_slope, col=trend_colors(100), main="Trend of Persistence Over Time", legend=TRUE)
  }
  
  if (!is.null(duration_slope)) {
    plot(duration_slope, col=trend_colors(100), main="Trend of Duration Over Time", legend=TRUE)
  }
  
  if (!is.null(concentration_slope)) {
    plot(concentration_slope, col=trend_colors(100), main="Trend of Concentration Over Time", legend=TRUE)
  }
  
  # Classify the trends based on significance and directionality using ifel function
  if (!is.null(persistence_pvalue)) {
    persistence_significance_direction <- ifel(persistence_pvalue <= alpha & persistence_slope > 0, 1,
                                               ifel(persistence_pvalue <= alpha & persistence_slope < 0, -1, 0))
    plot(persistence_significance_direction, col=c("red", "white", "blue"), main="Significance and Directionality of Persistence Trends", legend=TRUE)
  }
  
  if (!is.null(duration_pvalue)) {
    duration_significance_direction <- ifel(duration_pvalue <= alpha & duration_slope > 0, 1,
                                            ifel(duration_pvalue <= alpha & duration_slope < 0, -1, 0))
    plot(duration_significance_direction, col=c("red", "white", "blue"), main="Significance and Directionality of Duration Trends", legend=TRUE)
  }
  
  if (!is.null(concentration_pvalue)) {
    concentration_significance_direction <- ifel(concentration_pvalue <= alpha & concentration_slope > 0, 1,
                                                 ifel(concentration_pvalue <= alpha & concentration_slope < 0, -1, 0))
    plot(concentration_significance_direction, col=c("red", "white", "blue"), main="Significance and Directionality of Concentration Trends", legend=TRUE)
  }
}

# Example usage
analyze_sea_ice(start_year = 2014, end_year = 2023, use_mask = FALSE, report_metrics = c("concentration", "duration", "persistence"))



```




**Duration and Persistence + Trend analayis - Basic lm**


```{r}
# Load necessary libraries
library(terra)
library(dplyr)
library(lubridate)
library(nlme)
library(ggplot2)
library(grDevices)  # For colorRampPalette
library(gridExtra)  # For arranging plots side by side

# Define the function
analyze_sea_ice <- function(start_year, end_year, use_mask = TRUE, report_metrics = c("concentration", "duration", "persistence")) {
  
  # Define file paths
  chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"
  chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)
  study_area_shapefile <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp"
  
  # Load the study area shapefile
  if (use_mask) {
    study_area <- vect(study_area_shapefile)
  }
  
  # Define the threshold for sea ice concentration
  ice_threshold <- 15
  
  # Function to calculate consecutive days above threshold
  calculate_duration <- function(x, threshold) {
    if (all(is.na(x))) return(NA)
    rle_result <- rle(x > threshold)
    max_duration <- ifelse(any(rle_result$values), max(rle_result$lengths[rle_result$values]), 0)
    return(max_duration)
  }
  
  # Simplified function to process each chunk file using app
  process_chunk <- function(file_path) {
    region_name <- gsub(".*/|\\.nc$", "", file_path)
    message(paste("Processing file:", file_path))
    
    # Load the NSIDC sea ice concentration data for the subregion
    nsidc <- rast(file_path)
    
    annual_persistence <- list()
    annual_duration <- list()
    annual_concentration <- list()
    
    for (year in start_year:end_year) {
      message(paste("Processing year:", year))
      start_date <- as.Date(paste0(year, "-01-01"))
      end_date <- as.Date(paste0(year, "-12-31"))
      
      # Filter the sea ice data for the current year
      nsidc_year <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))
      
      if (nlyr(nsidc_year) == 0) {
        message(paste("No data for year:", year))
        next
      }
      
      # Calculate metrics based on options
      if ("persistence" %in% report_metrics) {
        persistence <- app(nsidc_year, function(x) sum(ifelse(x < ice_threshold, 0, 1), na.rm = FALSE))
        names(persistence) <- paste0("Persistence_", year)
        annual_persistence[[as.character(year)]] <- persistence
      }
#       
#       # Function to calculate persistence
# calculate_persistence <- function(x) {
#   persistence <- sum(x > ice_threshold, na.rm = TRUE)
#   if (all(is.na(x))) {
#     return(NA)
#   } else {
#     return(persistence)
#   }
# }
      
      if ("duration" %in% report_metrics) {
        duration <- app(nsidc_year, function(x) calculate_duration(x, ice_threshold))
        names(duration) <- paste0("Duration_", year)
        annual_duration[[as.character(year)]] <- duration
      }
      
      if ("concentration" %in% report_metrics) {
        concentration <- app(nsidc_year, function(x) mean(x, na.rm = TRUE))
        names(concentration) <- paste0("Concentration_", year)
        annual_concentration[[as.character(year)]] <- concentration
      }
    }
    
    message(paste("Finished processing file:", file_path))
    return(list(persistence = annual_persistence, duration = annual_duration, concentration = annual_concentration))
  }
  
  # Process each chunk file sequentially
  results <- lapply(chunk_files, process_chunk)
  
  # Combine all annual rasters into a single stack for the selected metrics
  combine_rasters <- function(raster_list) {
    raster_stack <- rast()
    for (year in names(raster_list)) {
      if (!is.null(raster_list[[year]])) {
        raster_stack <- c(raster_stack, raster_list[[year]])
      }
    }
    return(raster_stack)
  }
  
  persistence_stack <- NULL
  duration_stack <- NULL
  concentration_stack <- NULL
  
  if ("persistence" %in% report_metrics) {
    persistence_stack <- combine_rasters(do.call(c, lapply(results, `[[`, "persistence")))
    if (use_mask) persistence_stack <- mask(persistence_stack, study_area)
  }
  
  if ("duration" %in% report_metrics) {
    duration_stack <- combine_rasters(do.call(c, lapply(results, `[[`, "duration")))
    if (use_mask) duration_stack <- mask(duration_stack, study_area)
  }
  
  if ("concentration" %in% report_metrics) {
    concentration_stack <- combine_rasters(do.call(c, lapply(results, `[[`, "concentration")))
    if (use_mask) concentration_stack <- mask(concentration_stack, study_area)
  }
  
  # Function to apply linear model to each pixel and return slope and p-value
  apply_lm <- function(y) {
    if (all(is.na(y))) {
      return(c(NA, NA))
    } else {
      years <- start_year:end_year
      fit <- tryCatch(lm(y ~ years), error = function(e) return(NULL))
      if (is.null(fit)) {
        return(c(NA, NA))
      } else {
        slope <- coef(fit)[2]  # Slope of the linear model
        p_value <- summary(fit)$coefficients[2, 4]  # p-value for the slope
        return(c(slope, p_value))
      }
    }
  }
  
  persistence_trend <- NULL
  duration_trend <- NULL
  concentration_trend <- NULL
  
  if (!is.null(persistence_stack)) persistence_trend <- app(persistence_stack, apply_lm)
  if (!is.null(duration_stack)) duration_trend <- app(duration_stack, apply_lm)
  if (!is.null(concentration_stack)) concentration_trend <- app(concentration_stack, apply_lm)
  
  # Extract slopes and p-values from the results
  persistence_slope <- NULL
  persistence_pvalue <- NULL
  duration_slope <- NULL
  duration_pvalue <- NULL
  concentration_slope <- NULL
  concentration_pvalue <- NULL
  
  if (!is.null(persistence_trend)) {
    persistence_slope <- persistence_trend[[1]]
    persistence_pvalue <- persistence_trend[[2]]
  }
  
  if (!is.null(duration_trend)) {
    duration_slope <- duration_trend[[1]]
    duration_pvalue <- duration_trend[[2]]
  }
  
  if (!is.null(concentration_trend)) {
    concentration_slope <- concentration_trend[[1]]
    concentration_pvalue <- concentration_trend[[2]]
  }
  
  # Verify the integrity of the data
  if (!is.null(persistence_slope)) {
    print("Summary of persistence slope layer:")
    print(summary(persistence_slope))
    print("Summary of persistence p-value layer:")
    print(summary(persistence_pvalue))
  }
  
  if (!is.null(duration_slope)) {
    print("Summary of duration slope layer:")
    print(summary(duration_slope))
    print("Summary of duration p-value layer:")
    print(summary(duration_pvalue))
  }
  
  if (!is.null(concentration_slope)) {
    print("Summary of concentration slope layer:")
    print(summary(concentration_slope))
    print("Summary of concentration p-value layer:")
    print(summary(concentration_pvalue))
  }
  
  # Define a significance level
  alpha <- 0.05
  
  # Calculate statistics for persistence
  if (!is.null(persistence_slope)) {
    persistence_values <- values(persistence_slope)
    persistence_pvalues <- values(persistence_pvalue)
    persistence_data <- cbind(persistence_values, persistence_pvalues)
    persistence_data <- persistence_data[complete.cases(persistence_data), ]
    persistence_values <- persistence_data[, 1]
    persistence_pvalues <- persistence_data[, 2]
    persistence_mean <- mean(persistence_values)
    persistence_median <- median(persistence_values)
    persistence_min <- min(persistence_values)
    persistence_max <- max(persistence_values)
    persistence_significant <- sum(persistence_pvalues <= alpha) / length(persistence_pvalues) * 100
    persistence_positive <- sum(persistence_pvalues <= alpha & persistence_values > 0) / length(persistence_pvalues) * 100
    persistence_negative <- sum(persistence_pvalues <= alpha & persistence_values < 0) / length(persistence_pvalues) * 100
    persistence_nonsignificant <- 100 - persistence_significant
  }
  
  # Calculate statistics for duration
  if (!is.null(duration_slope)) {
    duration_values <- values(duration_slope)
    duration_pvalues <- values(duration_pvalue)
    duration_data <- cbind(duration_values, duration_pvalues)
    duration_data <- duration_data[complete.cases(duration_data), ]
    duration_values <- duration_data[, 1]
    duration_pvalues <- duration_data[, 2]
    duration_mean <- mean(duration_values)
    duration_median <- median(duration_values)
    duration_min <- min(duration_values)
    duration_max <- max(duration_values)
    duration_significant <- sum(duration_pvalues <= alpha) / length(duration_pvalues) * 100
    duration_positive <- sum(duration_pvalues <= alpha & duration_values > 0) / length(duration_pvalues) * 100
    duration_negative <- sum(duration_pvalues <= alpha & duration_values < 0) / length(duration_pvalues) * 100
    duration_nonsignificant <- 100 - duration_significant
  }
  
  # Calculate statistics for concentration
  if (!is.null(concentration_slope)) {
    concentration_values <- values(concentration_slope)
    concentration_pvalues <- values(concentration_pvalue)
    concentration_data <- cbind(concentration_values, concentration_pvalues)
    concentration_data <- concentration_data[complete.cases(concentration_data), ]
    concentration_values <- concentration_data[, 1]
    concentration_pvalues <- concentration_data[, 2]
    concentration_mean <- mean(concentration_values)
    concentration_median <- median(concentration_values)
    concentration_min <- min(concentration_values)
    concentration_max <- max(concentration_values)
    concentration_significant <- sum(concentration_pvalues <= alpha) / length(concentration_pvalues) * 100
    concentration_positive <- sum(concentration_pvalues <= alpha & concentration_values > 0) / length(concentration_pvalues) * 100
    concentration_negative <- sum(concentration_pvalues <= alpha & concentration_values < 0) / length(concentration_pvalues) * 100
    concentration_nonsignificant <- 100 - concentration_significant
  }
  
  # Print summary statistics for reporting
  if (!is.null(persistence_slope)) {
    persistence_summary <- data.frame(
      Metric = c("Mean slope", "Median slope", "Minimum slope", "Maximum slope", "% Significant", "% Positive", "% Negative", "% Non-significant"),
      Persistence = c(persistence_mean, persistence_median, persistence_min, persistence_max, persistence_significant, persistence_positive, persistence_negative, persistence_nonsignificant)
    )
    print(persistence_summary)
  }
  
  if (!is.null(duration_slope)) {
    duration_summary <- data.frame(
      Metric = c("Mean slope", "Median slope", "Minimum slope", "Maximum slope", "% Significant", "% Positive", "% Negative", "% Non-significant"),
      Duration = c(duration_mean, duration_median, duration_min, duration_max, duration_significant, duration_positive, duration_negative, duration_nonsignificant)
    )
    print(duration_summary)
  }
  
  if (!is.null(concentration_slope)) {
    concentration_summary <- data.frame(
      Metric = c("Mean slope", "Median slope", "Minimum slope", "Maximum slope", "% Significant", "% Positive", "% Negative", "% Non-significant"),
      Concentration = c(concentration_mean, concentration_median, concentration_min, concentration_max, concentration_significant, concentration_positive, concentration_negative, concentration_nonsignificant)
    )
    print(concentration_summary)
  }
  
  # Define a color palette for trends
  trend_colors <- colorRampPalette(c("red", "white", "blue"))
  
  # Set up multi-panel plotting environment
  par(mfrow = c(2, 3), mar = c(4, 4, 2, 1))
  
  if (!is.null(persistence_slope)) {
    plot(persistence_slope, col=trend_colors(100), main="Trend of Persistence Over Time", legend=TRUE, colNA="black")
  }
  
  if (!is.null(duration_slope)) {
    plot(duration_slope, col=trend_colors(100), main="Trend of Duration Over Time", legend=TRUE, colNA="black")
  }
  
  if (!is.null(concentration_slope)) {
    plot(concentration_slope, col=trend_colors(100), main="Trend of Concentration Over Time", legend=TRUE, colNA="black")
  }
  
  # Classify the trends based on significance and directionality using ifel function
  if (!is.null(persistence_pvalue)) {
    significant_cells <- persistence_pvalue <= alpha
    significant_mask <- ifel(significant_cells, 1, NA)
    positive_trend <- ifel(significant_mask == 1 & persistence_slope > 0, 1, NA)
    negative_trend <- ifel(significant_mask == 1 & persistence_slope < 0, 2, NA)
    na_mask <- ifel(is.na(persistence_slope), 3, NA)
    combined_trend <- positive_trend
    combined_trend[!is.na(negative_trend)] <- 2
    combined_trend[!is.na(na_mask)] <- 3
    color_table <- data.frame(value = c(1, 2, 3), col = c("blue", "red", "black"))
    coltab(combined_trend) <- color_table
    plot(combined_trend, main="Significance and Directionality of Persistence Trends")
    legend("topright", legend=c("Positive Trend", "Negative Trend", "NA Cells"), fill=color_table$col)
  }
  
  if (!is.null(duration_pvalue)) {
    significant_cells <- duration_pvalue <= alpha
    significant_mask <- ifel(significant_cells, 1, NA)
    positive_trend <- ifel(significant_mask == 1 & duration_slope > 0, 1, NA)
    negative_trend <- ifel(significant_mask == 1 & duration_slope < 0, 2, NA)
    na_mask <- ifel(is.na(duration_slope), 3, NA)
    combined_trend <- positive_trend
    combined_trend[!is.na(negative_trend)] <- 2
    combined_trend[!is.na(na_mask)] <- 3
    color_table <- data.frame(value = c(1, 2, 3), col = c("blue", "red", "black"))
    coltab(combined_trend) <- color_table
    plot(combined_trend, main="Significance and Directionality of Duration Trends")
    legend("topright", legend=c("Positive Trend", "Negative Trend", "NA Cells"), fill=color_table$col)
  }
  
  if (!is.null(concentration_pvalue)) {
    significant_cells <- concentration_pvalue <= alpha
    significant_mask <- ifel(significant_cells, 1, NA)
    positive_trend <- ifel(significant_mask == 1 & concentration_slope > 0, 1, NA)
    negative_trend <- ifel(significant_mask == 1 & concentration_slope < 0, 2, NA)
    na_mask <- ifel(is.na(concentration_slope), 3, NA)
    combined_trend <- positive_trend
    combined_trend[!is.na(negative_trend)] <- 2
    combined_trend[!is.na(na_mask)] <- 3
    color_table <- data.frame(value = c(1, 2, 3), col = c("blue", "red", "black"))
    coltab(combined_trend) <- color_table
    plot(combined_trend, main="Significance and Directionality of Concentration Trends")
    legend("topright", legend=c("Positive Trend", "Negative Trend", "NA Cells"), fill=color_table$col)
  }
}

# Example usage
analyze_sea_ice(start_year = 1987, end_year = 2023, use_mask = FALSE, report_metrics = c("concentration", "duration", "persistence"))



```















**Extent: Sea Ice Analysis: Generalized Least Squares**


```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(nlme)
library(wesanderson)
library(scales)

# Load your dataset
nsidc_metrics <- readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of ice extent for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_extent = mean(IceExtent_km, na.rm = TRUE), 
            sd_extent = sd(IceExtent_km, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Define a function to fit a GLS model for a given region and month
fit_gls_model <- function(region_data) {
  gls_model <- gls(mean_extent ~ Time, correlation = corAR1(), data = region_data)
  return(gls_model)
}

# Apply the model for each unique region and month combination and store the results
regions <- unique(monthly_averages$Region)
months <- unique(monthly_averages$Month)
gls_results <- list()

for (region in regions) {
  for (month in months) {
    region_month_data <- monthly_averages %>% filter(Region == region, Month == month)
    if (nrow(region_month_data) > 1) {
      gls_results[[paste(region, month, sep = "_")]] <- fit_gls_model(region_month_data)
    }
  }
}

# Display summary of the GLS model for each region and month
for (key in names(gls_results)) {
  cat("Region and Month:", key, "\n")
  print(summary(gls_results[[key]]))
  cat("\n")
}

# Directory to save the plots
output_directory <- "D:/Manuscripts_localData/FrostBound_AQ/Results/gls_trends"
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

# Color settings
sd_color <- "#7AB8BF"  # Light red color (you can adjust to your preferred shade)
axis_color <- "gray70"  # Light gray color for the axis lines

# Visualize the trend for each region and save the plots
for (region in regions) {
  region_data <- monthly_averages %>% filter(Region == region)
  
  p <- region_data %>%
    ggplot(aes(x = Year, y = mean_extent)) +
    geom_errorbar(aes(ymin = mean_extent - sd_extent, ymax = mean_extent + sd_extent), 
                  width = 0.2, color = sd_color) +
    geom_point(color = "black") +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    facet_wrap(~month2, scales = "fixed", ncol = 3) +
    xlab(NULL) +
    ylab(bquote("Ice extent" ~ (km^2 %*% 10^6))) +
    scale_y_continuous(labels = scales::scientific) +
    labs(
      title = sprintf(
        "%s: Sea ice extent between %d and %d",
        region,
        min(region_data$Year),
        max(region_data$Year)
      ),
      # subtitle = "The vertical bar at each point shows the standard deviation around the mean. The blue line represents the linear trend.",
      caption = "Source: NSIDC 25.5 km Sea Ice Index dataset"
    ) +
    theme(
      plot.caption = element_text(size = 8, color = "black"),
      plot.margin = unit(c(5.5, 10, 5.5, 5.5), "points"),
      panel.background = element_rect(fill = "white"),
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(colour = "black", size = 12, face = "bold"),
      panel.grid = element_blank(),
      axis.line = element_line(color = axis_color),
      legend.position = "none"
    )
  
  # Save the plot
  ggsave(filename = paste(output_directory, paste("25km_Extent_trend_plot_", region, ".png", sep = ""), sep = "/"), plot = p)
  

  # Save the plot as EPS
  ggsave(filename = paste(output_directory, paste("25km_Extent_trend_plot_", region, ".eps", sep = ""), sep = "/"), plot = p, device = "eps")
}


# Extract and print coefficients and p-values for each region and month
coefficients_gls <- lapply(gls_results, function(model) summary(model)$tTable)
names(coefficients_gls) <- names(gls_results)

# Print coefficients and p-values
for (key in names(coefficients_gls)) {
  cat("Region and Month:", key, "\n")
  print(coefficients_gls[[key]])
  cat("\n")
}


```





**Concentration: Sea Ice Analysis - Generalized Least Squares**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(nlme)
library(wesanderson)
library(scales)

# Load your dataset
nsidc_metrics <-readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

str(nsidc_metrics)
# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of sea ice concentration for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_concentration = mean(MeanSIC, na.rm = TRUE), 
            sd_concentration = sd(MeanSIC, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Define a function to fit a GLS model for a given region and month
fit_gls_model <- function(region_data) {
  gls_model <- gls(mean_concentration ~ Time, correlation = corAR1(), data = region_data)
  return(gls_model)
}

# Apply the model for each unique region and month combination and store the results
regions <- unique(monthly_averages$Region)
months <- unique(monthly_averages$Month)
gls_results <- list()

for (region in regions) {
  for (month in months) {
    region_month_data <- monthly_averages %>% filter(Region == region, Month == month)
    if (nrow(region_month_data) > 1) {
      gls_results[[paste(region, month, sep = "_")]] <- fit_gls_model(region_month_data)
    }
  }
}

# Display summary of the GLS model for each region and month
for (key in names(gls_results)) {
  cat("Region and Month:", key, "\n")
  print(summary(gls_results[[key]]))
  cat("\n")
}

# Directory to save the plots
output_directory <- "D:/Manuscripts_localData/FrostBound_AQ/Results/gls_trends"
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

# Color settings
sd_color <- "#7AB8BF"  # Light red color 
axis_color <- "gray70"  # Light gray color for the axis lines

# Visualize the trend for each region and save the plots
for (region in regions) {
  region_data <- monthly_averages %>% filter(Region == region)
  
  p <- region_data %>%
    ggplot(aes(x = Year, y = mean_concentration)) +
    geom_errorbar(aes(ymin = mean_concentration - sd_concentration, ymax = mean_concentration + sd_concentration), 
                  width = 0.2, color = sd_color) +
    geom_point(color = "black") +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    facet_wrap(~month2, scales = "fixed", ncol = 3) +
    xlab(NULL) +
    ylab("Mean Sea Ice Concentration (%)") +
    labs(
      title = sprintf(
        "%s: Sea ice concentration between %d and %d",
        region,
        min(region_data$Year),
        max(region_data$Year)
      ),
      subtitle = "The vertical bar at each point shows the standard deviation around the mean. The blue line represents the linear trend.",
      caption = "Source: NSIDC 25km Sea Ice Index dataset"
    ) +
    theme(
      plot.caption = element_text(size = 8, color = "black"),
      plot.margin = unit(c(5.5, 10, 5.5, 5.5), "points"),
      panel.background = element_rect(fill = "white"),
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(colour = "black", size = 12, face = "bold"),
      panel.grid = element_blank(),
      axis.line = element_line(color = axis_color),
      legend.position = "none"
    )
  
  # Save the plot
  ggsave(filename = paste(output_directory, paste("25km_Concentration_trend_plot_", region, ".png", sep = ""), sep = "/"), plot = p)
  
  # Save the plot as EPS
  ggsave(filename = paste(output_directory, paste("25km_Concentration_trend_plot_", region, ".eps", sep = ""), sep = "/"), plot = p, device = "eps")
}

# Extract and print coefficients and p-values for each region and month
coefficients_gls <- lapply(gls_results, function(model) summary(model)$tTable)
names(coefficients_gls) <- names(gls_results)

# Print coefficients and p-values
for (key in names(coefficients_gls)) {
  cat("Region and Month:", key, "\n")
  print(coefficients_gls[[key]])
  cat("\n")
}


```


**Southern Oscillation Index Analysis**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(httr)
library(tidyr)
library(broom)
library(gridExtra)
library(RColorBrewer)

# Load your dataset
nsidc_metrics <- readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of ice extent for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_extent = mean(IceExtent_km, na.rm = TRUE), 
            sd_extent = sd(IceExtent_km, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Load SOI data
url <- "https://www.cpc.ncep.noaa.gov/data/indices/soi"
soi_raw <- GET(url)
soi_text <- content(soi_raw, "text")

# Preprocess the SOI data
soi_lines <- strsplit(soi_text, "\n")[[1]]

# Identify the start of the standardized SOI data section
standardized_soi_start <- grep("STANDARDIZED    DATA", soi_lines)

# Extract standardized SOI data lines
soi_standardized_lines <- soi_lines[(standardized_soi_start + 3):length(soi_lines)]
soi_standardized_lines <- soi_standardized_lines[!grepl("-999.9", soi_standardized_lines)] # remove lines with invalid data

# Convert standardized SOI data to dataframe
soi_data <- read.table(text = soi_standardized_lines, fill = TRUE, stringsAsFactors = FALSE)
colnames(soi_data) <- c("Year", month.abb)
soi_data <- soi_data %>% mutate(Year = as.integer(Year))

# Convert to long format
soi_data_long <- soi_data %>%
  pivot_longer(-Year, names_to = "Month", values_to = "SOI") %>%
  mutate(Month = match(Month, month.abb), 
         Year = as.integer(Year),
         SOI = as.numeric(SOI)) %>%
  filter(!is.na(SOI))  # Remove rows with NA values in SOI

# Merge sea ice data with SOI data
merged_data <- merge(monthly_averages, soi_data_long, by = c("Year", "Month"))

# Remove duplicate rows
merged_data <- merged_data[!duplicated(merged_data), ]

# Calculate correlation for each region and month
correlation_results <- merged_data %>%
  group_by(Region, Month) %>%
  summarize(correlation = cor(mean_extent, SOI, use = "complete.obs"),
            p.value = cor.test(mean_extent, SOI)$p.value) %>%
  arrange(Region, Month)

# Print the correlation results
print(correlation_results)




# Visualize the correlation results using RColorBrewer color palette
ggplot(correlation_results, aes(x = factor(Month, levels = 6:9), y = correlation, fill = Region)) +
  geom_bar(stat = "identity", position = position_dodge(0.9)) +
  geom_text(aes(label = round(correlation, 2)), vjust = -1.5, position = position_dodge(0.9)) +
  scale_fill_brewer(palette = "Set3") +  # You can choose other palettes like "Paired", "Dark2", etc.
  labs(title = "Correlation between SOI and Sea Ice Extent by Region and Month",
       x = "Month", y = "Correlation") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom"
  )




# Linear regression analysis to quantify the relationship between SOI and sea ice extent
regression_results <- merged_data %>%
  group_by(Region, Month) %>%
  do(tidy(lm(mean_extent ~ SOI, data = .)))

# Print regression results
print(regression_results)

# Filter the regression results for the SOI term
soi_coefficients <- regression_results %>%
  filter(term == "SOI")

# Function to create a plot for each region
plot_soi_effect <- function(region_data) {
  ggplot(region_data, aes(x = factor(Month), y = estimate, color = factor(Month))) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(
      title = paste("Effect of SOI on Sea Ice Extent:", unique(region_data$Region)),
      x = "Month",
      y = "SOI Coefficient Estimate",
      color = "Month"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5),
      legend.position = "none"
    )
}

# Apply the function for each region and plot
unique_regions <- unique(soi_coefficients$Region)
plots <- lapply(unique_regions, function(region) {
  region_data <- soi_coefficients %>% filter(Region == region)
  plot_soi_effect(region_data)
})

# Display the plots
do.call(grid.arrange, c(plots, ncol = 2))

# # Create a combined plot showing the SOI coefficients for all regions and months
# ggplot(soi_coefficients, aes(x = factor(Month), y = estimate, color = Region)) +
#   geom_point(size = 3) +
#   geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
#   geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
#   labs(
#     title = "Effect of SOI on Sea Ice Extent Across Regions and Months",
#     x = "Month",
#     y = "SOI Coefficient Estimate",
#     color = "Region"
#   ) +
#   theme_minimal() +
#   theme(
#     plot.title = element_text(hjust = 0.5)
  # )

# Create individual plots for each region and arrange them using facet_wrap
ggplot(soi_coefficients, aes(x = factor(Month), y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~ Region, scales = "free_y") +
  labs(
    title = "Effect of SOI on Sea Ice Extent Across Regions and Months",
    x = "Month",
    y = "SOI Coefficient Estimate"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )


```






