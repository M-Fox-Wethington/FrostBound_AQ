---
title: "Sea Ice Trend Analysis - NSIDC"
author: "Michael Wethington"
date: "2024-05-14"
output: html_document
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include=FALSE}
library(terra)

```

## **Dataset Overview**

```{r Data Overview}

nsidc_winter <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack/NSIDC_25km_Full_Study_Area.nc"

nsidc_winter <- rast(nsidc_winter)

# Print the object to see its structure
print(nsidc_winter)

# Summary of the object
summary(nsidc_winter)

str(nsidc_winter)

# If it's a SpatRaster, use terra functions to explore further
if (inherits(nsidc_winter, "SpatRaster")) {
  # Check the number of layers
  nlyr(nsidc_winter)
  
  # Extract dates from raster layer names or metadata
  winter_dates <- time(nsidc_winter)

# Extract unique months from the dates
  unique_months <- unique(month(winter_dates))
  
  print(unique_months)
  
  # Get the names of the layers
  names(nsidc_winter)
  
  # Plot a single layer
  plot(nsidc_winter[[1]])
  
  # Get the extent of the raster
  ext(nsidc_winter)
  
  # Get the resolution of the raster
  res(nsidc_winter)
  
  # Check the CRS (Coordinate Reference System)
  crs(nsidc_winter)
} else {
  print("The object is not a SpatRaster. Further exploration is needed.")
}


summary(nsidc_winter[[1]])

plot(nsidc_winter[[1]])

rm(nsidc_winter)
```




**Calculate Regional Sea Ice Metrics (Parallel)**

```{r Calculate Regional Ice Extent Metrics}


library(terra)        # For raster data manipulation
library(doParallel)   # For parallel processing
library(foreach)      # For looping with parallel support
library(dplyr)
library(lubridate)

# Function to calculate mean SIC and sea ice extent for a given raster layer within a file
calculate_layer_stats <- function(layer_index, file_path) {
  raster_stack <- rast(file_path)                  # Load the raster stack from file
  layer_data <- raster_stack[[layer_index]]        # Extract the specific layer
  
  layer_date <- time(layer_data)                   # Extract date from layer metadata

  # Handle sea ice concentration: treat cells < 15 as 0
  layer_data[layer_data < 15] <- 0
  
  # Calculate mean SIC excluding NAs
  mean_sic <- as.numeric(terra::global(layer_data, fun = 'mean', na.rm = TRUE))  
  
  # Handle sea ice extent: count cells >= 15
  valid_ice_cells <- sum(values(layer_data) >= 15, na.rm = TRUE)
  cell_area_sq_meters <- prod(res(layer_data))    # Calculate the area of one cell in square meters
  total_ice_area_sq_km <- (valid_ice_cells * cell_area_sq_meters) / 1e6  # Convert total ice area to square kilometers
  
  rm(raster_stack, layer_data)   # Clear memory
  gc()                           # Run garbage collection
  
  # Extract region name from the file path
  region_name <- tools::file_path_sans_ext(basename(file_path))
  region_name <- sub("NSIDC_25km_", "", region_name)  # Adjust based on actual pattern in filenames
  
  return(list(mean_sic = mean_sic, ice_extent_km = total_ice_area_sq_km, date = layer_date, region = region_name))
}

# Directory with chunk files for each region
chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"

chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)  # List all .nc files for each region


all_results <- list()  # Initialize list to store results from all chunks

for (r_fp in chunk_files) {
  numCores <- detectCores() - 1
  cl <- makeCluster(numCores)
  registerDoParallel(cl)
  
  clusterExport(cl, varlist = c("calculate_layer_stats", "r_fp"))
  
  results <- foreach(i = 1:nlyr(rast(r_fp)), .packages = 'terra', .errorhandling = "pass") %dopar% {
    tryCatch({
      calculate_layer_stats(i, r_fp)
    }, error = function(e) {
      return(list(error = TRUE, message = e$message))
    })
  }
  
  stopCluster(cl)
  
  # Append chunk results to overall results, add file path to results for region tracking
  all_results <- c(all_results, lapply(results, function(x) c(x, file = r_fp)))
}

# Convert list of all results into a dataframe, handling possible errors
final_result_df <- do.call(rbind, lapply(all_results, function(x) {
  if (!is.null(x$error)) {
    return(data.frame(Date = NA, MeanSIC = NA, IceExtent_km = NA, Region = NA, error = x$message))
  } else {
    return(data.frame(Date = x$date, MeanSIC = x$mean_sic, IceExtent_km = x$ice_extent_km, Region = x$region, error = NA))
  }
}))

# Add year, month, and day columns
final_result_df <- final_result_df %>%
  dplyr::mutate(Year = year(Date), Month = month(Date), Day = day(Date))

# Filter for Full_Study_Area and June, July, August, and September
final_result_df <- final_result_df %>%
  filter(Month %in% c(6, 7, 8, 9))

# Save combined results to CSV and RDS for further use
write.csv(final_result_df, "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.csv", row.names = FALSE)
saveRDS(final_result_df, "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")



```
**Sea Ice Duration**
```{r}

# Load necessary libraries
library(terra)
library(dplyr)
library(lubridate)

# Define the directory containing the subregion files
chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"
chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)

# Define the threshold for sea ice concentration
ice_threshold <- 15

# Define the date range for analysis
start_date <- as.Date("2021-01-01")
end_date <- as.Date("2022-12-31")

# Simplified function to process each chunk file using app
process_chunk <- function(file_path) {
  region_name <- gsub(".*/|\\.nc$", "", file_path)  # Extract the region name from the file path
  message(paste("Processing file:", file_path))
  
  # Load the NSIDC sea ice concentration data for the subregion
  nsidc <- rast(file_path)
  print("Loaded NSIDC data:")
  print(nsidc)
  
  # Filter the sea ice data from 2021 to 2022
  nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))
  print("Filtered NSIDC data:")
  print(nsidc)
  
  # Count the number of days with ice concentration above the threshold for each pixel
  valid_obs <- app(nsidc, function(x) sum(x > ice_threshold, na.rm = TRUE))
  names(valid_obs) <- "Count_Above_Threshold"
  
  # Calculate the statistics for each annual raster layer
  stats <- data.frame(
    Region = region_name,
    Min_Days = min(valid_obs[], na.rm = TRUE),
    Max_Days = max(valid_obs[], na.rm = TRUE),
    Mean_Days = mean(valid_obs[], na.rm = TRUE),
    Median_Days = median(valid_obs[], na.rm = TRUE),
    Start_Date = start_date,
    End_Date = end_date
  )
  
  # Plot the raster
  plot(valid_obs, main = paste("Sea Ice Concentration Above Threshold for", region_name), col = hcl.colors(100, "Blues", rev = TRUE))
  
  return(stats)
}

# Process each chunk file sequentially
results <- lapply(chunk_files, process_chunk)

# Combine all results into a single dataframe
count_obs_df <- do.call(rbind, results)

# View the results
print(count_obs_df)



```


**Sea Ice Persistence Trend**


```{r}

# Load necessary libraries
library(terra)
library(sf)
library(dplyr)
library(ggplot2)
library(lubridate)
library(nlme)

# Load study area shapefile
study_area_path <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp"
study_area <- st_read(study_area_path)

# Load the NSIDC sea ice concentration data
nsidc <- rast("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/NSIDC_25km_Study-Area.nc")

# Filter the sea ice data from 1980 to 2022
start_date <- as.Date("2010-01-01")
end_date <- as.Date("2022-12-31")
nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))

# Mask the sea ice data with the study area
study_area_mask <- mask(nsidc, vect(study_area))

# Extract all years for processing
all_years <- unique(year(time(study_area_mask)))

# Define winter months (June-September)
winter_months <- c(6, 7, 8, 9)

# Define a function to count days with ice cover > 15% for each year and each month
count_ice_days <- function(x) {
  ice_days <- sum(x > 15, na.rm = TRUE)
  return(ice_days)
}

# Initialize empty lists to store the monthly ice day count rasters
annual_ice_days_june <- list()
annual_ice_days_july <- list()
annual_ice_days_august <- list()
annual_ice_days_september <- list()

# Loop over each year, subset the raster stack for each month, and apply the counting function
for (year in all_years) {
  for (month in winter_months) {
    month_rasters <- subset(study_area_mask, which(year(time(study_area_mask)) == year & month(time(study_area_mask)) == month))
    if (nlyr(month_rasters) > 0) {
      ice_days_raster <- app(month_rasters, count_ice_days)  # app inherently operates cell-wise
      names(ice_days_raster) <- paste("Ice_Days", year, month, sep="_")
      if (month == 6) annual_ice_days_june[[as.character(year)]] <- ice_days_raster
      if (month == 7) annual_ice_days_july[[as.character(year)]] <- ice_days_raster
      if (month == 8) annual_ice_days_august[[as.character(year)]] <- ice_days_raster
      if (month == 9) annual_ice_days_september[[as.character(year)]] <- ice_days_raster
      print(paste("Processed year:", year, "month:", month))
    } else {
      print(paste("No data for year:", year, "month:", month))
    }
  }
}

# Combine the annual rasters into separate stacks for each month
annual_ice_days_stack_june <- rast(annual_ice_days_june)
annual_ice_days_stack_july <- rast(annual_ice_days_july)
annual_ice_days_stack_august <- rast(annual_ice_days_august)
annual_ice_days_stack_september <- rast(annual_ice_days_september)

# Calculate the proportion of open water days for each month and year
calculate_open_water_days <- function(annual_ice_days_stack, years) {
  open_water_days <- sapply(years, function(y) {
    ice_days_raster <- subset(annual_ice_days_stack, names(annual_ice_days_stack) == as.character(y))
    open_water_prop <- global(ice_days_raster, fun = function(x) mean(x < 15, na.rm = TRUE))
    return(open_water_prop)
  })
  return(open_water_days)
}

open_water_days_june <- calculate_open_water_days(annual_ice_days_stack_june, all_years)
open_water_days_july <- calculate_open_water_days(annual_ice_days_stack_july, all_years)
open_water_days_august <- calculate_open_water_days(annual_ice_days_stack_august, all_years)
open_water_days_september <- calculate_open_water_days(annual_ice_days_stack_september, all_years)

# Convert the open water days to data frames for analysis
open_water_df_june <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_june))
open_water_df_july <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_july))a
open_water_df_august <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_august))
open_water_df_september <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_september))

# Perform GLS analysis for each month to examine the long-term trends
gls_model_june <- gls(open_water_prop ~ year, data = open_water_df_june, correlation = corAR1())
gls_model_july <- gls(open_water_prop ~ year, data = open_water_df_july, correlation = corAR1())
gls_model_august <- gls(open_water_prop ~ year, data = open_water_df_august, correlation = corAR1())
gls_model_september <- gls(open_water_prop ~ year, data = open_water_df_september, correlation = corAR1())

# Summarize the GLS models
summary(gls_model_june)
summary(gls_model_july)
summary(gls_model_august)
summary(gls_model_september)

# Visualize the long-term trends for each month
ggplot(open_water_df_june, aes(x = year, y = open_water_prop)) +
  geom_line() +
  geom_smooth(method = "lm", se = TRUE) +
  theme_minimal() +
  labs(title = "Long-term Trend of Open Water Days in June",
       x = "Year",
       y = "Proportion of Open Water Days")

ggplot(open_water_df_july, aes(x = year, y = open_water_prop)) +
  geom_line() +
  geom_smooth(method = "lm", se = TRUE) +
  theme_minimal() +
  labs(title = "Long-term Trend of Open Water Days in July",
       x = "Year",
       y = "Proportion of Open Water Days")

ggplot(open_water_df_august, aes(x = year, y = open_water_prop)) +
  geom_line() +
  geom_smooth(method = "lm", se = TRUE) +
  theme_minimal() +
  labs(title = "Long-term Trend of Open Water Days in August",
       x = "Year",
       y = "Proportion of Open Water Days")

ggplot(open_water_df_september, aes(x = year, y = open_water_prop)) +
  geom_line() +
  geom_smooth(method = "lm", se = TRUE) +
  theme_minimal() +
  labs(title = "Long-term Trend of Open Water Days in September",
       x = "Year",
       y = "Proportion of Open Water Days")

# Analyze trends for the entire study area and subregions
subregions <- split(study_area, study_area$subregion_id)

subregion_results <- lapply(subregions, function(subregion) {
  subregion_mask <- mask(nsidc, vect(subregion))
  
  subregion_open_water_days <- sapply(all_years, function(y) {
    subregion_year_rasters <- subset(subregion_mask, which(year(time(subregion_mask)) == y))
    open_water_prop <- global(subregion_year_rasters, fun = function(x) mean(x < 15, na.rm = TRUE))
    return(open_water_prop)
  })
  
  return(data.frame(year = all_years, open_water_prop = unlist(subregion_open_water_days), subregion_id = unique(subregion$subregion_id)))
})

subregion_open_water_df <- do.call(rbind, subregion_results)

# Perform GLS analysis for each subregion
subregion_gls_results <- subregion_open_water_df %>%
  group_by(subregion_id) %>%
  do(model = gls(open_water_prop ~ year, data = ., correlation = corAR1()))

# Summarize GLS models for subregions
subregion_gls_summaries <- subregion_gls_results %>%
  summarise(model_summary = list(summary(model)))

# Visualize long-term trends for subregions
ggplot(subregion_open_water_df, aes(x = year, y = open_water_prop, color = factor(subregion_id))) +
  geom_line() +
  geom_smooth(method = "lm", se = TRUE) +
  theme_minimal() +
  labs(title = "Long-term Trend of Open Water Days by Subregion",
       x = "Year",
       y = "Proportion of Open Water Days",
       color = "Subregion ID")




```



**Persistence analysis - under production**
```{r}
# Load necessary libraries
library(terra)
library(sf)
library(dplyr)
library(ggplot2)
library(lubridate)
library(nlme)

# Define the directory containing the subregion files
chunk_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack"
chunk_files <- list.files(chunk_dir, pattern = "\\.nc$", full.names = TRUE)

# Define a function to process each chunk file
process_chunk <- function(file_path) {
  region_name <- gsub(".*/|\\.nc$", "", file_path)  # Extract the region name from the file path
  message(paste("Processing file:", file_path))
  
  # Load the NSIDC sea ice concentration data for the subregion
  nsidc <- rast(file_path)
  
  # Filter the sea ice data from 2010 to 2022
  start_date <- as.Date("2010-01-01")
  end_date <- as.Date("2022-12-31")
  nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))
  
  # Extract all years for processing
  all_years <- unique(year(time(nsidc)))
  
  # Define winter months (June-September)
  winter_months <- c(6, 7, 8, 9)
  
  # Define a function to count days with ice cover > 15% for each year and each month
  count_ice_days <- function(x) {
    ice_days <- sum(x > 15, na.rm = TRUE)
    return(ice_days)
  }
  
  # Initialize empty lists to store the monthly and annual ice day count rasters
  annual_ice_days <- list()
  annual_ice_days_june <- list()
  annual_ice_days_july <- list()
  annual_ice_days_august <- list()
  annual_ice_days_september <- list()
  
  # Loop over each year, subset the raster stack for each month and annual, and apply the counting function
  for (year in all_years) {
    year_rasters <- subset(nsidc, which(year(time(nsidc)) == year))
    if (nlyr(year_rasters) > 0) {
      ice_days_raster <- app(year_rasters, count_ice_days)
      names(ice_days_raster) <- paste("Ice_Days", year, "Annual", sep="_")
      annual_ice_days[[as.character(year)]] <- ice_days_raster
    }
    
    for (month in winter_months) {
      month_rasters <- subset(nsidc, which(year(time(nsidc)) == year & month(time(nsidc)) == month))
      if (nlyr(month_rasters) > 0) {
        ice_days_raster <- app(month_rasters, count_ice_days)  # app inherently operates cell-wise
        names(ice_days_raster) <- paste("Ice_Days", year, month, sep="_")
        if (month == 6) annual_ice_days_june[[as.character(year)]] <- ice_days_raster
        if (month == 7) annual_ice_days_july[[as.character(year)]] <- ice_days_raster
        if (month == 8) annual_ice_days_august[[as.character(year)]] <- ice_days_raster
        if (month == 9) annual_ice_days_september[[as.character(year)]] <- ice_days_raster
        message(paste("Processed year:", year, "month:", month))
      } else {
        message(paste("No data for year:", year, "month:", month))
      }
    }
  }
  
  # Combine the annual rasters into separate stacks for each month and for the entire year
  annual_ice_days_stack <- rast(annual_ice_days)
  annual_ice_days_stack_june <- rast(annual_ice_days_june)
  annual_ice_days_stack_july <- rast(annual_ice_days_july)
  annual_ice_days_stack_august <- rast(annual_ice_days_august)
  annual_ice_days_stack_september <- rast(annual_ice_days_september)
  
  # Calculate the proportion of open water days for each year and each month
  calculate_open_water_days <- function(annual_ice_days_stack, years) {
    open_water_days <- sapply(years, function(y) {
      ice_days_raster <- subset(annual_ice_days_stack, names(annual_ice_days_stack) == as.character(y))
      open_water_prop <- global(ice_days_raster, fun = function(x) mean(x < 15, na.rm = TRUE))
      return(open_water_prop)
    })
    return(open_water_days)
  }
  
  open_water_days_annual <- calculate_open_water_days(annual_ice_days_stack, all_years)
  open_water_days_june <- calculate_open_water_days(annual_ice_days_stack_june, all_years)
  open_water_days_july <- calculate_open_water_days(annual_ice_days_stack_july, all_years)
  open_water_days_august <- calculate_open_water_days(annual_ice_days_stack_august, all_years)
  open_water_days_september <- calculate_open_water_days(annual_ice_days_stack_september, all_years)
  
  # Convert the open water days to data frames for analysis
  open_water_df_annual <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_annual))
  open_water_df_june <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_june))
  open_water_df_july <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_july))
  open_water_df_august <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_august))
  open_water_df_september <- data.frame(year = all_years, open_water_prop = unlist(open_water_days_september))
  
  # Function to perform GLS analysis and check for sufficient data
  perform_gls <- function(df) {
    if (sum(!is.na(df$open_water_prop)) < 2) {
      return(NULL)
    }
    tryCatch({
      model <- gls(open_water_prop ~ year, data = df, correlation = corAR1())
      return(summary(model))
    }, error = function(e) {
      message(paste("Error in GLS analysis:", e$message))
      return(NULL)
    })
  }
  
  # Perform GLS analysis for each period to examine the long-term trends
  summary_annual <- perform_gls(open_water_df_annual)
  summary_june <- perform_gls(open_water_df_june)
  summary_july <- perform_gls(open_water_df_july)
  summary_august <- perform_gls(open_water_df_august)
  summary_september <- perform_gls(open_water_df_september)
  
  message(paste("Summary for Annual in region:", region_name))
  print(summary_annual)
  
  message(paste("Summary for June in region:", region_name))
  print(summary_june)
  
  message(paste("Summary for July in region:", region_name))
  print(summary_july)
  
  message(paste("Summary for August in region:", region_name))
  print(summary_august)
  
  message(paste("Summary for September in region:", region_name))
  print(summary_september)
  
  # Visualize the long-term trends for each period
  if (!is.null(summary_annual)) {
    p_annual <- ggplot(open_water_df_annual, aes(x = year, y = open_water_prop)) +
      geom_line() +
      geom_smooth(method = "lm", se = TRUE) +
      theme_minimal() +
      labs(title = paste("Long-term Trend of Open Water Days (Annual) -", region_name),
           x = "Year",
           y = "Proportion of Open Water Days")
    
    ggsave(filename = paste0("Trend_Annual_", region_name, ".png"), plot = p_annual, width = 10, height = 6)
  }
  
  if (!is.null(summary_june)) {
    p_june <- ggplot(open_water_df_june, aes(x = year, y = open_water_prop)) +
      geom_line() +
      geom_smooth(method = "lm", se = TRUE) +
      theme_minimal() +
      labs(title = paste("Long-term Trend of Open Water Days in June -", region_name),
           x = "Year",
           y = "Proportion of Open Water Days")
    
    ggsave(filename = paste0("Trend_June_", region_name, ".png"), plot = p_june, width = 10, height = 6)
  }
  
  if (!is.null(summary_july)) {
    p_july <- ggplot(open_water_df_july, aes(x = year, y = open_water_prop)) +
      geom_line() +
      geom_smooth(method = "lm", se = TRUE) +
      theme_minimal() +
      labs(title = paste("Long-term Trend of Open Water Days in July -", region_name),
           x = "Year",
           y = "Proportion of Open Water Days")
    
    ggsave(filename = paste0("Trend_July_", region_name, ".png"), plot = p_july, width = 10, height = 6)
  }
  
  if (!is.null(summary_august)) {
    p_august <- ggplot(open_water_df_august, aes(x = year, y = open_water_prop)) +
      geom_line() +
      geom_smooth(method = "lm", se = TRUE) +
      theme_minimal() +
      labs(title = paste("Long-term Trend of Open Water Days in August -", region_name),
           x = "Year",
           y = "Proportion of Open Water Days")
    
    ggsave(filename = paste0("Trend_August_", region_name, ".png"), plot = p_august, width = 10, height = 6)
  }
  
  if (!is.null(summary_september)) {
    p_september <- ggplot(open_water_df_september, aes(x = year, y = open_water_prop)) +
      geom_line() +
      geom_smooth(method = "lm", se = TRUE) +
      theme_minimal() +
      labs(title = paste("Long-term Trend of Open Water Days in September -", region_name),
           x = "Year",
           y = "Proportion of Open Water Days")
    
    ggsave(filename = paste0("Trend_September_", region_name, ".png"), plot = p_september, width = 10, height = 6)
  }
  
  return(list(Region = region_name, 
              Annual = summary_annual, 
              June = summary_june, 
              July = summary_july, 
              August = summary_august, 
              September = summary_september))
}

# Process each chunk file sequentially
results <- lapply(chunk_files, process_chunk)

# Print all results
print(results)


```










**Extent: Sea Ice Analysis: Generalized Least Squares**


```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(nlme)
library(wesanderson)
library(scales)

# Load your dataset
nsidc_metrics <- readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of ice extent for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_extent = mean(IceExtent_km, na.rm = TRUE), 
            sd_extent = sd(IceExtent_km, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Define a function to fit a GLS model for a given region and month
fit_gls_model <- function(region_data) {
  gls_model <- gls(mean_extent ~ Time, correlation = corAR1(), data = region_data)
  return(gls_model)
}

# Apply the model for each unique region and month combination and store the results
regions <- unique(monthly_averages$Region)
months <- unique(monthly_averages$Month)
gls_results <- list()

for (region in regions) {
  for (month in months) {
    region_month_data <- monthly_averages %>% filter(Region == region, Month == month)
    if (nrow(region_month_data) > 1) {
      gls_results[[paste(region, month, sep = "_")]] <- fit_gls_model(region_month_data)
    }
  }
}

# Display summary of the GLS model for each region and month
for (key in names(gls_results)) {
  cat("Region and Month:", key, "\n")
  print(summary(gls_results[[key]]))
  cat("\n")
}

# Directory to save the plots
output_directory <- "D:/Manuscripts_localData/FrostBound_AQ/Results/gls_trends"
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

# Color settings
sd_color <- "#7AB8BF"  # Light red color (you can adjust to your preferred shade)
axis_color <- "gray70"  # Light gray color for the axis lines

# Visualize the trend for each region and save the plots
for (region in regions) {
  region_data <- monthly_averages %>% filter(Region == region)
  
  p <- region_data %>%
    ggplot(aes(x = Year, y = mean_extent)) +
    geom_errorbar(aes(ymin = mean_extent - sd_extent, ymax = mean_extent + sd_extent), 
                  width = 0.2, color = sd_color) +
    geom_point(color = "black") +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    facet_wrap(~month2, scales = "fixed", ncol = 3) +
    xlab(NULL) +
    ylab(bquote("Ice extent" ~ (km^2 %*% 10^6))) +
    scale_y_continuous(labels = scales::scientific) +
    labs(
      title = sprintf(
        "%s: Sea ice extent between %d and %d",
        region,
        min(region_data$Year),
        max(region_data$Year)
      ),
      # subtitle = "The vertical bar at each point shows the standard deviation around the mean. The blue line represents the linear trend.",
      caption = "Source: NSIDC 25.5 km Sea Ice Index dataset"
    ) +
    theme(
      plot.caption = element_text(size = 8, color = "black"),
      plot.margin = unit(c(5.5, 10, 5.5, 5.5), "points"),
      panel.background = element_rect(fill = "white"),
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(colour = "black", size = 12, face = "bold"),
      panel.grid = element_blank(),
      axis.line = element_line(color = axis_color),
      legend.position = "none"
    )
  
  # Save the plot
  ggsave(filename = paste(output_directory, paste("25km_Extent_trend_plot_", region, ".png", sep = ""), sep = "/"), plot = p)
  

  # Save the plot as EPS
  ggsave(filename = paste(output_directory, paste("25km_Extent_trend_plot_", region, ".eps", sep = ""), sep = "/"), plot = p, device = "eps")
}


# Extract and print coefficients and p-values for each region and month
coefficients_gls <- lapply(gls_results, function(model) summary(model)$tTable)
names(coefficients_gls) <- names(gls_results)

# Print coefficients and p-values
for (key in names(coefficients_gls)) {
  cat("Region and Month:", key, "\n")
  print(coefficients_gls[[key]])
  cat("\n")
}


```





**Concentration: Sea Ice Analysis - Generalized Least Squares**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(nlme)
library(wesanderson)
library(scales)

# Load your dataset
nsidc_metrics <-readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

str(nsidc_metrics)
# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of sea ice concentration for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_concentration = mean(MeanSIC, na.rm = TRUE), 
            sd_concentration = sd(MeanSIC, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Define a function to fit a GLS model for a given region and month
fit_gls_model <- function(region_data) {
  gls_model <- gls(mean_concentration ~ Time, correlation = corAR1(), data = region_data)
  return(gls_model)
}

# Apply the model for each unique region and month combination and store the results
regions <- unique(monthly_averages$Region)
months <- unique(monthly_averages$Month)
gls_results <- list()

for (region in regions) {
  for (month in months) {
    region_month_data <- monthly_averages %>% filter(Region == region, Month == month)
    if (nrow(region_month_data) > 1) {
      gls_results[[paste(region, month, sep = "_")]] <- fit_gls_model(region_month_data)
    }
  }
}

# Display summary of the GLS model for each region and month
for (key in names(gls_results)) {
  cat("Region and Month:", key, "\n")
  print(summary(gls_results[[key]]))
  cat("\n")
}

# Directory to save the plots
output_directory <- "D:/Manuscripts_localData/FrostBound_AQ/Results/gls_trends"
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

# Color settings
sd_color <- "#7AB8BF"  # Light red color 
axis_color <- "gray70"  # Light gray color for the axis lines

# Visualize the trend for each region and save the plots
for (region in regions) {
  region_data <- monthly_averages %>% filter(Region == region)
  
  p <- region_data %>%
    ggplot(aes(x = Year, y = mean_concentration)) +
    geom_errorbar(aes(ymin = mean_concentration - sd_concentration, ymax = mean_concentration + sd_concentration), 
                  width = 0.2, color = sd_color) +
    geom_point(color = "black") +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    facet_wrap(~month2, scales = "fixed", ncol = 3) +
    xlab(NULL) +
    ylab("Mean Sea Ice Concentration (%)") +
    labs(
      title = sprintf(
        "%s: Sea ice concentration between %d and %d",
        region,
        min(region_data$Year),
        max(region_data$Year)
      ),
      subtitle = "The vertical bar at each point shows the standard deviation around the mean. The blue line represents the linear trend.",
      caption = "Source: NSIDC 25km Sea Ice Index dataset"
    ) +
    theme(
      plot.caption = element_text(size = 8, color = "black"),
      plot.margin = unit(c(5.5, 10, 5.5, 5.5), "points"),
      panel.background = element_rect(fill = "white"),
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(colour = "black", size = 12, face = "bold"),
      panel.grid = element_blank(),
      axis.line = element_line(color = axis_color),
      legend.position = "none"
    )
  
  # Save the plot
  ggsave(filename = paste(output_directory, paste("25km_Concentration_trend_plot_", region, ".png", sep = ""), sep = "/"), plot = p)
  
  # Save the plot as EPS
  ggsave(filename = paste(output_directory, paste("25km_Concentration_trend_plot_", region, ".eps", sep = ""), sep = "/"), plot = p, device = "eps")
}

# Extract and print coefficients and p-values for each region and month
coefficients_gls <- lapply(gls_results, function(model) summary(model)$tTable)
names(coefficients_gls) <- names(gls_results)

# Print coefficients and p-values
for (key in names(coefficients_gls)) {
  cat("Region and Month:", key, "\n")
  print(coefficients_gls[[key]])
  cat("\n")
}


```


**Southern Oscillation Index Analysis**

```{r}
# Load necessary libraries
library(dplyr)
library(lubridate)
library(ggplot2)
library(httr)
library(tidyr)
library(broom)
library(gridExtra)
library(RColorBrewer)

# Load your dataset
nsidc_metrics <- readRDS("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/analysis/NSIDC_25km_Daily_Metrics.rds")

# Filter for winter months (June - September) and add Year, Month, and Day columns
winter_metrics <- nsidc_metrics %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  filter(Month %in% c(6, 7, 8, 9))

# Calculate monthly averages of ice extent for each region
monthly_averages <- winter_metrics %>%
  group_by(Year, Month, Region) %>%
  summarise(mean_extent = mean(IceExtent_km, na.rm = TRUE), 
            sd_extent = sd(IceExtent_km, na.rm = TRUE), .groups = 'drop') %>%
  ungroup()

# Create a time variable for trend analysis
monthly_averages <- monthly_averages %>%
  mutate(Time = as.numeric(Year) + (Month - 1) / 12,
         month2 = month(ymd(paste(Year, Month, 1)), label = TRUE, abbr = FALSE))

# Load SOI data
url <- "https://www.cpc.ncep.noaa.gov/data/indices/soi"
soi_raw <- GET(url)
soi_text <- content(soi_raw, "text")

# Preprocess the SOI data
soi_lines <- strsplit(soi_text, "\n")[[1]]

# Identify the start of the standardized SOI data section
standardized_soi_start <- grep("STANDARDIZED    DATA", soi_lines)

# Extract standardized SOI data lines
soi_standardized_lines <- soi_lines[(standardized_soi_start + 3):length(soi_lines)]
soi_standardized_lines <- soi_standardized_lines[!grepl("-999.9", soi_standardized_lines)] # remove lines with invalid data

# Convert standardized SOI data to dataframe
soi_data <- read.table(text = soi_standardized_lines, fill = TRUE, stringsAsFactors = FALSE)
colnames(soi_data) <- c("Year", month.abb)
soi_data <- soi_data %>% mutate(Year = as.integer(Year))

# Convert to long format
soi_data_long <- soi_data %>%
  pivot_longer(-Year, names_to = "Month", values_to = "SOI") %>%
  mutate(Month = match(Month, month.abb), 
         Year = as.integer(Year),
         SOI = as.numeric(SOI)) %>%
  filter(!is.na(SOI))  # Remove rows with NA values in SOI

# Merge sea ice data with SOI data
merged_data <- merge(monthly_averages, soi_data_long, by = c("Year", "Month"))

# Remove duplicate rows
merged_data <- merged_data[!duplicated(merged_data), ]

# Calculate correlation for each region and month
correlation_results <- merged_data %>%
  group_by(Region, Month) %>%
  summarize(correlation = cor(mean_extent, SOI, use = "complete.obs"),
            p.value = cor.test(mean_extent, SOI)$p.value) %>%
  arrange(Region, Month)

# Print the correlation results
print(correlation_results)




# Visualize the correlation results using RColorBrewer color palette
ggplot(correlation_results, aes(x = factor(Month, levels = 6:9), y = correlation, fill = Region)) +
  geom_bar(stat = "identity", position = position_dodge(0.9)) +
  geom_text(aes(label = round(correlation, 2)), vjust = -1.5, position = position_dodge(0.9)) +
  scale_fill_brewer(palette = "Set3") +  # You can choose other palettes like "Paired", "Dark2", etc.
  labs(title = "Correlation between SOI and Sea Ice Extent by Region and Month",
       x = "Month", y = "Correlation") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom"
  )




# Linear regression analysis to quantify the relationship between SOI and sea ice extent
regression_results <- merged_data %>%
  group_by(Region, Month) %>%
  do(tidy(lm(mean_extent ~ SOI, data = .)))

# Print regression results
print(regression_results)

# Filter the regression results for the SOI term
soi_coefficients <- regression_results %>%
  filter(term == "SOI")

# Function to create a plot for each region
plot_soi_effect <- function(region_data) {
  ggplot(region_data, aes(x = factor(Month), y = estimate, color = factor(Month))) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(
      title = paste("Effect of SOI on Sea Ice Extent:", unique(region_data$Region)),
      x = "Month",
      y = "SOI Coefficient Estimate",
      color = "Month"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5),
      legend.position = "none"
    )
}

# Apply the function for each region and plot
unique_regions <- unique(soi_coefficients$Region)
plots <- lapply(unique_regions, function(region) {
  region_data <- soi_coefficients %>% filter(Region == region)
  plot_soi_effect(region_data)
})

# Display the plots
do.call(grid.arrange, c(plots, ncol = 2))

# # Create a combined plot showing the SOI coefficients for all regions and months
# ggplot(soi_coefficients, aes(x = factor(Month), y = estimate, color = Region)) +
#   geom_point(size = 3) +
#   geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
#   geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
#   labs(
#     title = "Effect of SOI on Sea Ice Extent Across Regions and Months",
#     x = "Month",
#     y = "SOI Coefficient Estimate",
#     color = "Region"
#   ) +
#   theme_minimal() +
#   theme(
#     plot.title = element_text(hjust = 0.5)
  # )

# Create individual plots for each region and arrange them using facet_wrap
ggplot(soi_coefficients, aes(x = factor(Month), y = estimate)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~ Region, scales = "free_y") +
  labs(
    title = "Effect of SOI on Sea Ice Extent Across Regions and Months",
    x = "Month",
    y = "SOI Coefficient Estimate"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )


```








```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```


```{r}
```




```{r}
```





```{r}
```





```{r}
```
