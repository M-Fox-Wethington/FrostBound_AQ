---
title: "Gentoo Model Parameter Abundance Model"
author: "Michael J. Wethington"
date: "2024-06-04"
output: html_document
---


zi = latent nest abundance (mean-adjusted)

lz = logged abundance (re-expression of above):  lzi,t=log(zi,t). for the ith site in the tth year,

ri = intrinsic growth rate

lp = predicted population growth rate multiplier
la = actual population growth rate multiplier 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```





```{r}

# Load required libraries
library(tidyverse)
library(coda)
library(mapppdr)
library(patchwork)
library(leaflet)
library(CCAMLRGIS)
library(rjags)
library(MCMCvis)
library(parallel)
library(stringi)
library(pander)
library(testthat)

# Define parameters
min_season <- 1970
max_season <- 2023
species <- "GEPE"

# Construct Presence-Absence Assumptions CSV for the JAGS model
penguin_obs <- mapppdr::penguin_obs

penguin_obs_processed <- penguin_obs %>%
  filter(species_id == species) %>%
  mutate(
    presence = ifelse(!is.na(count), 1, 0),
    known_w = 1) %>%
  select(site_id, season, presence, known_w, count, accuracy, type)

presence_absence_assumptions <- expand.grid(
  site_id = unique(penguin_obs$site_id),
  season = min_season:max_season
) %>%
  left_join(penguin_obs_processed, by = c("site_id", "season")) %>%
  mutate(
    presence = ifelse(is.na(presence), 0, presence),
    known_w = ifelse(is.na(known_w), 0, known_w),
    count = ifelse(is.na(count), 0, count)) %>%
  group_by(site_id, season) %>%
  arrange(desc(type), desc(accuracy), .by_group = TRUE) %>%
  slice(1) %>%
  ungroup() %>%
  select(site_id, season, presence, known_w, count, accuracy)

# Load the JAGS MCMC Output File
load("D:/Manuscripts_localData/FrostBound_AQ/Results/gentoo-abundance-model/model_data_rinits_output.rda")

# Extract the Gentoo Abundance Estimates (lz)
model_samples <- as.matrix(model_data_rinits_output)

# Filter columns that are logged latent abundance (lz) parameters
lz_columns <- grep("^lz\\[", colnames(model_samples))
lz_samples <- model_samples[, lz_columns]

# Convert log-abundances to actual abundances
abundance_samples <- exp(lz_samples)

# Summarize the actual abundances
abundance_summary <- apply(abundance_samples, 2, function(x) {
  c(mean = mean(x), median = median(x), 
    lower_95 = quantile(x, 0.025), upper_95 = quantile(x, 0.975))
})

# Convert to a readable data frame (use t to transpose)
abundance_summary_df <- as.data.frame(t(abundance_summary))

# Extract site and season info from the indices
extract_indices <- function(colname) {
  indices <- gsub("[^0-9,]", "", colname)
  as.integer(unlist(strsplit(indices, ",")))
}

indices <- lapply(colnames(abundance_samples), extract_indices)
sites <- sapply(indices, `[`, 1)
seasons <- sapply(indices, `[`, 2)

abundance_summary_df$site <- sites
abundance_summary_df$season <- seasons

abundance_summary_df <- abundance_summary_df %>% 
  rename(mean_abundance = mean,
         median_abundance = median,
         lower_95_abundance = "lower_95.2.5%",
         upper_95_abundance = "upper_95.97.5%")

head(abundance_summary_df)

# Load and prepare SiteList
SiteList <- mapppdr::penguin_obs %>%
  filter(count > 0 & species_id == species & season >= min_season & season <= max_season) %>%
  mutate(season_relative = season - min_season + 1) %>%
  group_by(site_id) %>%
  summarise(initial_season = min(season_relative)) %>%
  ungroup() %>%
  left_join(mapppdr::sites, by = "site_id") %>%
  mutate(site = as.numeric(as.factor(site_id))) %>%
  select(site_id, site_name, ccamlr_id, site, initial_season, latitude, longitude)

(n_sites <- nrow(SiteList))

SiteList %>% 
  distinct(site, site_id, latitude, longitude)

# Join SiteList with abundance_summary_df
final_data <- left_join(SiteList, abundance_summary_df, by = "site")

# Ensure final_data is sorted by site and season
final_data <- final_data %>%
  arrange(site, season)

# Calculate the growth rate and append it to the data
final_data <- final_data %>%
  group_by(site) %>%
  mutate(growth_rate = mean_abundance / lag(mean_abundance)) %>%
  ungroup()

# Adjust the season column in the final data
final_data <- final_data %>%
  mutate(year = 1970 + season - 1)

# Display the adjusted final_data
print(head(final_data))

write.csv(final_data, "D:/Manuscripts_localData/FrostBound_AQ/Results/gentoo-abundance-model/modeled_gentoo_parameters.csv")
# Print the head of the final data with growth rates
print(head(final_data))

```


```{r}
library(ggplot2)
library(dplyr)

# Calculate geometric mean of growth rates
final_data <- final_data %>%
  group_by(site) %>%
  mutate(geometric_mean_growth_rate = exp(mean(log(growth_rate), na.rm = TRUE))) %>%
  ungroup()

# Filter data for the specific site
site_data <- final_data %>% filter(site_id == "AITC")

# Calculate the mean growth multiplier for the site
mean_growth <- site_data %>% 
  summarize(mean_growth_multiplier = exp(mean(log(growth_rate), na.rm = TRUE)),
            lower_ci = exp(mean(log(growth_rate), na.rm = TRUE) - 1.96 * sd(log(growth_rate), na.rm = TRUE)/sqrt(n())),
            upper_ci = exp(mean(log(growth_rate), na.rm = TRUE) + 1.96 * sd(log(growth_rate), na.rm = TRUE)/sqrt(n())))

# Check if the 'count' and 'type' columns exist and correct them if needed
if (!"count" %in% names(site_data)) {
  site_data$count <- site_data$mean_abundance # or any other logic that fits
}

if (!"type" %in% names(site_data)) {
  site_data$type <- "nests" # default type, adjust as necessary
}

# Add year column based on season
site_data <- site_data %>%
  mutate(year = 1970 + season - 1)

# Generate the plot
ggplot(site_data, aes(x = year, y = mean_abundance)) +
  geom_boxplot(aes(group = year), fill = "orange", alpha = 0.6) +
  geom_errorbar(aes(ymin = lower_95_abundance, ymax = upper_95_abundance), width = 0.2) +
  geom_point(data = site_data %>% filter(!is.na(count)), aes(y = count, color = type), size = 3, shape = 21, fill = "blue") +
  scale_color_manual(values = c("nests" = "red", "chicks" = "blue")) +
  labs(title = "AITC, Barrientos Island (Aitcho Islands), 48.1",
       subtitle = paste0("mean population growth multiplier = ", round(mean_growth$mean_growth_multiplier, 3), 
                         " (", round(mean_growth$lower_ci, 2), " - ", round(mean_growth$upper_ci, 2), ")"),
       x = "Year",
       y = "Abundance",
       color = "Type") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))


```





**Sea Ice Concentration Analysis2 (Home Range Analysis)**
```{r}
# Load necessary libraries
library(terra)
library(sf)
library(dplyr)
library(ggplot2)
library(lubridate)
library(nlme)

# Function to compute mean SIC for all valid years within the specified buffer
compute_mean_sic <- function(buffer_path, nsidc, ice_threshold = 15, winter_months = c(6, 7, 8, 9)) {
  combined_buffers_sf <- st_read(buffer_path)
  dissolved_buffer <- st_union(combined_buffers_sf)
  buffer_mask <- mask(nsidc, vect(dissolved_buffer))
  all_years <- unique(year(time(buffer_mask)))
  
  mean_sic_per_year <- data.frame(year = all_years, mean_sic = NA)
  
  for (year in all_years) {
    winter_data <- subset(buffer_mask, which(year(time(buffer_mask)) == year & month(time(buffer_mask)) %in% winter_months))
    if (nlyr(winter_data) > 0) {
      winter_data <- app(winter_data, function(x) ifelse(x < ice_threshold, 0, x))
      mean_sic <- global(winter_data, fun = mean, na.rm = TRUE)
      mean_sic_per_year$mean_sic[mean_sic_per_year$year == year] <- mean_sic[1, 1]
    }
  }
  
  return(mean_sic_per_year)
}

# Function to get precomputed mean SIC
get_precomputed_sic <- function(years, mean_sic_per_year) {
  valid_years <- years[years >= 1980 & years <= 2022]
  if (length(valid_years) == 0) {
    return(NA)
  }
  mean_sic_values <- mean_sic_per_year$mean_sic[mean_sic_per_year$year %in% valid_years]
  if (length(mean_sic_values) > 0) {
    return(mean(mean_sic_values, na.rm = TRUE))
  } else {
    return(NA)
  }
}

# Function to fit GLS models and summarize results
fit_gls_models <- function(penguin_abundance_filtered, mean_sic_per_year) {
  penguin_abundance_filtered <- penguin_abundance_filtered %>%
    rowwise() %>%
    mutate(overwinter_sic_1yr = ifelse(year - 1 >= 1980, get_precomputed_sic(year - 1, mean_sic_per_year), NA),
           overwinter_sic_2yr = ifelse(year - 2 >= 1980, get_precomputed_sic(c(year - 1, year - 2), mean_sic_per_year), NA),
           overwinter_sic_3yr = ifelse(year - 3 >= 1980, get_precomputed_sic(c(year - 1, year - 2, year - 3), mean_sic_per_year), NA),
           overwinter_sic_4yr = ifelse(year - 4 >= 1980, get_precomputed_sic(c(year - 1, year - 2, year - 3, year - 4), mean_sic_per_year), NA),
           overwinter_sic_5yr = ifelse(year - 5 >= 1980, get_precomputed_sic(c(year - 1, year - 2, year - 3, year - 4, year - 5), mean_sic_per_year), NA)) %>%
    ungroup() %>%
    filter(!is.na(overwinter_sic_1yr) & !is.na(overwinter_sic_2yr) & !is.na(overwinter_sic_3yr) & !is.na(overwinter_sic_4yr) & !is.na(overwinter_sic_5yr))
  
  results <- list()
  
  for (lag in 1:5) {
    formula <- as.formula(paste("growth_rate ~ overwinter_sic_", lag, "yr", sep = ""))
    model <- gls(formula, correlation = corAR1(form = ~1 | site_id), data = penguin_abundance_filtered)
    summary_model <- summary(model)
    results[[paste("Lag", lag)]] <- list(
      AIC = AIC(model),
      BIC = BIC(model),
      coefficients = summary_model$tTable,
      p_value = summary_model$tTable[2, 4]
    )
  }
  
  return(results)
}

# Load Gentoo penguin data
penguin_data <- read.csv("D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/gentoo_presence_absence_assumptions.csv")
penguin_abundance_data <- read.csv("D:/Manuscripts_localData/FrostBound_AQ/Results/gentoo-abundance-model/modeled_gentoo_parameters.csv")

# Load study area shapefile
study_area_path <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp"
study_area <- st_read(study_area_path)

# Load the NSIDC sea ice concentration data
nsidc <- rast("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/NSIDC_25km_Study-Area.nc")

# Filter the sea ice data from 1980 to 2022
start_date <- as.Date("1980-01-01")
end_date <- as.Date("2022-12-31")
nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))

# Adjust the season column in the penguin abundance data
penguin_abundance_data <- penguin_abundance_data %>%
  mutate(year = 1970 + season - 1)

# Filter penguin data to keep only consecutively censused sites and clean duplicates
consecutively_censused <- penguin_data %>%
  arrange(site_id, season) %>%
  group_by(site_id) %>%
  mutate(next_season = lead(season),
         next_presence = lead(presence)) %>%
  filter(presence == 1 & next_presence == 1 & season != next_season) %>%
  ungroup() %>%
  select(site_id, season, presence, next_season)

# Merge with penguin abundance data
penguin_abundance_filtered <- penguin_abundance_data %>%
  left_join(consecutively_censused, by = c("site_id", "year" = "season")) %>%
  filter(!is.na(next_season))

print("Penguin abundance data after filtering for consecutively censused sites:")
print(head(penguin_abundance_filtered)) # Debug print

# Define home range directory and sizes
home_range_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/gentoo-home-ranges-updated/"
home_range_sizes <- c(50, 100, 150, 200, 250, 300, 350, 400, 450, 500)

# Loop through each home range size and compute results
all_results <- list()

for (size in home_range_sizes) {
  buffer_path <- file.path(home_range_dir, paste0("gepe_home_ranges_", size, "km.shp"))
  mean_sic_per_year <- compute_mean_sic(buffer_path, nsidc)
  results <- fit_gls_models(penguin_abundance_filtered, mean_sic_per_year)
  all_results[[paste(size, "km")]] <- results
}

# Print the results
for (size in names(all_results)) {
  cat("Home Range Size:", size, "\n")
  for (lag in names(all_results[[size]])) {
    cat(lag, "Lag:\n")
    cat("  AIC:", all_results[[size]][[lag]]$AIC, "\n")
    cat("  BIC:", all_results[[size]][[lag]]$BIC, "\n")
    cat("  Coefficients:\n")
    print(all_results[[size]][[lag]]$coefficients)
    cat("  P-Value:", all_results[[size]][[lag]]$p_value, "\n")
  }
  cat("\n")
}


```




**Gentoo Sea Ice Persistence (Proportion of Open Water Days) Analysis**

    For each year in the study period, calculate the proportion of open water days (days with sea ice concentration below a threshold of 15%) during winter months

Multi-Year Lag Effects

```{r}

# Load necessary libraries
library(terra)
library(sf)
library(dplyr)
library(ggplot2)
library(lubridate)
library(nlme)

# Function to compute mean sea ice persistence for all valid years within the specified buffer
compute_mean_persistence <- function(buffer_path, nsidc, ice_threshold = 15, winter_months = c(6, 7, 8, 9)) {
  combined_buffers_sf <- st_read(buffer_path)
  dissolved_buffer <- st_union(combined_buffers_sf)
  buffer_mask <- mask(nsidc, vect(dissolved_buffer))
  all_years <- unique(year(time(buffer_mask)))
  
  mean_persistence_per_year <- data.frame(year = all_years, mean_persistence = NA)
  
  for (year in all_years) {
    winter_data <- subset(buffer_mask, which(year(time(buffer_mask)) == year & month(time(buffer_mask)) %in% winter_months))
    if (nlyr(winter_data) > 0) {
      # Calculate the proportion of open water days
      open_water_prop <- app(winter_data, function(x) mean(x < ice_threshold, na.rm = TRUE))
      mean_persistence <- global(open_water_prop, fun = mean, na.rm = TRUE)
      mean_persistence_per_year$mean_persistence[mean_persistence_per_year$year == year] <- mean_persistence[1, 1]
    }
  }
  
  return(mean_persistence_per_year)
}

# Function to get precomputed mean persistence
get_precomputed_persistence <- function(years, mean_persistence_per_year) {
  valid_years <- years[years >= 1980 & years <= 2022]
  if (length(valid_years) == 0) {
    return(NA)
  }
  mean_persistence_values <- mean_persistence_per_year$mean_persistence[mean_persistence_per_year$year %in% valid_years]
  if (length(mean_persistence_values) > 0) {
    return(mean(mean_persistence_values, na.rm = TRUE))
  } else {
    return(NA)
  }
}

# Function to fit GLS models and summarize results
fit_gls_models <- function(penguin_abundance_filtered, mean_persistence_per_year) {
  penguin_abundance_filtered <- penguin_abundance_filtered %>%
    rowwise() %>%
    mutate(overwinter_persistence_1yr = ifelse(year - 1 >= 1980, get_precomputed_persistence(year - 1, mean_persistence_per_year), NA),
           overwinter_persistence_2yr = ifelse(year - 2 >= 1980, get_precomputed_persistence(c(year - 1, year - 2), mean_persistence_per_year), NA),
           overwinter_persistence_3yr = ifelse(year - 3 >= 1980, get_precomputed_persistence(c(year - 1, year - 2, year - 3), mean_persistence_per_year), NA),
           overwinter_persistence_4yr = ifelse(year - 4 >= 1980, get_precomputed_persistence(c(year - 1, year - 2, year - 3, year - 4), mean_persistence_per_year), NA),
           overwinter_persistence_5yr = ifelse(year - 5 >= 1980, get_precomputed_persistence(c(year - 1, year - 2, year - 3, year - 4, year - 5), mean_persistence_per_year), NA)) %>%
    ungroup() %>%
    filter(!is.na(overwinter_persistence_1yr) & !is.na(overwinter_persistence_2yr) & !is.na(overwinter_persistence_3yr) & !is.na(overwinter_persistence_4yr) & !is.na(overwinter_persistence_5yr))
  
  results <- list()
  
  for (lag in 1:5) {
    formula <- as.formula(paste("growth_rate ~ overwinter_persistence_", lag, "yr", sep = ""))
    model <- gls(formula, correlation = corAR1(form = ~1 | site_id), data = penguin_abundance_filtered)
    summary_model <- summary(model)
    results[[paste("Lag", lag)]] <- list(
      AIC = AIC(model),
      BIC = BIC(model),
      coefficients = summary_model$tTable,
      p_value = summary_model$tTable[2, 4]
    )
  }
  
  return(results)
}

# Load Gentoo penguin data
penguin_data <- read.csv("D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/gentoo_presence_absence_assumptions.csv")
penguin_abundance_data <- read.csv("D:/Manuscripts_localData/FrostBound_AQ/Results/gentoo-abundance-model/modeled_gentoo_parameters.csv")

# Load study area shapefile
study_area_path <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp"
study_area <- st_read(study_area_path)

# Load the NSIDC sea ice concentration data
nsidc <- rast("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack/NSIDC_25km_Full_Study_Area.nc")

# Filter the sea ice data from 1980 to 2022
start_date <- as.Date("2005-01-01")
end_date <- as.Date("2023-09-30")
nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))


# Adjust the season column in the penguin abundance data
penguin_abundance_data <- penguin_abundance_data %>%
  mutate(year = 1970 + season - 1)

# Filter penguin data to keep only consecutively censused sites and clean duplicates
consecutively_censused <- penguin_data %>%
  arrange(site_id, season) %>%
  group_by(site_id) %>%
  mutate(next_season = lead(season),
         next_presence = lead(presence)) %>%
  filter(presence == 1 & next_presence == 1 & season != next_season) %>%
  ungroup() %>%
  select(site_id, season, presence, next_season)

# Merge with penguin abundance data
penguin_abundance_filtered <- penguin_abundance_data %>%
  left_join(consecutively_censused, by = c("site_id", "year" = "season")) %>%
  filter(!is.na(next_season))

print("Penguin abundance data after filtering for consecutively censused sites:")
print(head(penguin_abundance_filtered)) # Debug print

# Define home range directory and sizes
home_range_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/gentoo-home-ranges-updated/"
home_range_sizes <- c(25, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500)
# home_range_sizes <- c(50, 100, 150, 200, 250, 300, 350, 400, 450, 500)

# Loop through each home range size and compute results
all_results <- list()

for (size in home_range_sizes) {
  buffer_path <- file.path(home_range_dir, paste0("gepe_home_ranges_", size, "km.shp"))
  mean_persistence_per_year <- compute_mean_persistence(buffer_path, nsidc)
  results <- fit_gls_models(penguin_abundance_filtered, mean_persistence_per_year)
  all_results[[paste(size, "km")]] <- results
}

# Print the results
for (size in names(all_results)) {
  cat("Home Range Size:", size, "\n")
  for (lag in names(all_results[[size]])) {
    cat(lag, "Lag:\n")
    cat("  AIC:", all_results[[size]][[lag]]$AIC, "\n")
    cat("  BIC:", all_results[[size]][[lag]]$BIC, "\n")
    cat("  Coefficients:\n")
    print(all_results[[size]][[lag]]$coefficients)
    cat("  P-Value:", all_results[[size]][[lag]]$p_value, "\n")
  }
  cat("\n")
}

```

**Duration**

```{r}
# Load necessary libraries
library(terra)
library(sf)
library(dplyr)
library(nlme)
library(stringr)  # Add this line to load stringr package

# Function to compute mean duration of sea ice concentration above a threshold
compute_mean_duration <- function(buffer_path, nsidc, threshold = 15, winter_months = c(6, 7, 8, 9)) {
  combined_buffers_sf <- st_read(buffer_path)
  dissolved_buffer <- st_union(combined_buffers_sf)
  buffer_mask <- mask(nsidc, vect(dissolved_buffer))
  all_years <- unique(year(time(buffer_mask)))
  
  mean_duration_results <- data.frame(year = all_years, mean_duration = NA)
  
  for (year in all_years) {
    winter_data <- subset(buffer_mask, which(year(time(buffer_mask)) == year & month(time(buffer_mask)) %in% winter_months))
    if (nlyr(winter_data) > 0) {
      durations <- app(winter_data, function(x) {
        rle_result <- rle(x > threshold)
        durations <- rle_result$lengths[rle_result$values]
        return(mean(durations, na.rm = TRUE))
      })
      mean_duration <- mean(values(durations), na.rm = TRUE)
      
      # Debugging print statements
      print(paste("Year:", year, "Mean Duration:", mean_duration))
      
      mean_duration_results$mean_duration[mean_duration_results$year == year] <- mean_duration
    }
  }
  
  return(mean_duration_results)
}

# Function to fit GLS models and summarize results
fit_gls_models <- function(penguin_abundance_filtered, duration_metrics) {
  results <- list()
  for (lag in 1:5) {
    penguin_abundance_filtered <- penguin_abundance_filtered %>%
      rowwise() %>%
      mutate(!!paste0("overwinter_duration_", lag, "yr") := ifelse(year - lag >= 1980, duration_metrics$mean_duration[duration_metrics$year == year - lag], NA)) %>%
      ungroup()
  }
  
  for (lag in 1:5) {
    penguin_abundance_filtered_lag <- penguin_abundance_filtered %>%
      filter(!is.na(!!sym(paste0("overwinter_duration_", lag, "yr"))))
    
    formula <- as.formula(paste("growth_rate ~ overwinter_duration_", lag, "yr", sep = ""))
    model <- gls(formula, correlation = corAR1(form = ~1 | site_id), data = penguin_abundance_filtered_lag)
    summary_model <- summary(model)
    
    results[[paste("Lag", lag, sep = "_")]] <- list(
      AIC = AIC(model),
      BIC = BIC(model),
      coefficients = summary_model$tTable,
      p_value = summary_model$tTable[2, 4]
    )
  }
  
  return(results)
}

# Load Gentoo penguin data
penguin_data <- read.csv("D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/gentoo_presence_absence_assumptions.csv")
penguin_abundance_data <- read.csv("D:/Manuscripts_localData/FrostBound_AQ/Results/gentoo-abundance-model/modeled_gentoo_parameters.csv")

# Load study area shapefile
study_area_path <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/gis-layers/study-area/shp/subregions/Frostbound_AQ_Subregions_EPSG_3976.shp"
study_area <- st_read(study_area_path)

# Load the NSIDC sea ice concentration data
nsidc <- rast("D:/Manuscripts_localData/FrostBound_AQ/Datasets/25km_Sea-Ice-Index/stack/substack/NSIDC_25km_Full_Study_Area.nc")

# Filter the sea ice data from 2005 to 2023
start_date <- as.Date("2005-01-01")
end_date <- as.Date("2023-09-30")
nsidc <- subset(nsidc, which(time(nsidc) >= start_date & time(nsidc) <= end_date))

# Adjust the season column in the penguin abundance data
penguin_abundance_data <- penguin_abundance_data %>%
  mutate(year = 1970 + season - 1)

# Filter penguin data to keep only consecutively censused sites and clean duplicates
consecutively_censused <- penguin_data %>%
  arrange(site_id, season) %>%
  group_by(site_id) %>%
  mutate(next_season = lead(season),
         next_presence = lead(presence)) %>%
  filter(presence == 1 & next_presence == 1 & season != next_season) %>%
  ungroup() %>%
  select(site_id, season, presence, next_season)

# Merge with penguin abundance data
penguin_abundance_filtered <- penguin_abundance_data %>%
  left_join(consecutively_censused, by = c("site_id", "year" = "season")) %>%
  filter(!is.na(next_season))

print("Penguin abundance data after filtering for consecutively censused sites:")
print(head(penguin_abundance_filtered)) # Debug print

# Define home range directory
home_range_dir <- "D:/Manuscripts_localData/FrostBound_AQ/Datasets/mapppd/gentoo-home-ranges-updated/"
home_range_files <- list.files(home_range_dir, pattern = "\\.shp$", full.names = TRUE)

# Loop through each home range shapefile and compute results
all_results <- list()

for (buffer_path in home_range_files) {
  home_range_size <- str_extract(buffer_path, "(\\d+)km")
  duration_metrics <- compute_mean_duration(buffer_path, nsidc)
  results <- fit_gls_models(penguin_abundance_filtered, duration_metrics)
  all_results[[home_range_size]] <- results
}

print(all_results)


```

